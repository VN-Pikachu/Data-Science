{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".box {\n",
       "    border: 1px double dodgerblue;\n",
       "    padding: 5px;\n",
       "}\n",
       ".note {\n",
       "    font-size: 20;\n",
       "    color: teal;\n",
       "    font-weight: bold;\n",
       "}\n",
       ".highlight {\n",
       "    color: green;\n",
       "    font-family: verdana;\n",
       "}\n",
       ".tag {\n",
       "    background: red;\n",
       "    color: white;\n",
       "    padding: 3px;\n",
       "}\n",
       ".warning {\n",
       "    background: red;\n",
       "    padding: 12px;\n",
       "    font-size: 24px;\n",
       "    color: white;\n",
       "    text-align: center;\n",
       "    font-family: verdana;\n",
       "}\n",
       ".symbol {\n",
       "    color: white;\n",
       "    background: green;\n",
       "    font-size: 20px;\n",
       "    padding: 2px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run convention.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.96\n",
      "Test score: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state = 6)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('svm', SVC())])\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Train score: %.2f' % pipe.score(X_train, y_train))\n",
    "print('Test score: %.2f' % pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pipelines in Grid searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'warning'>Parameter name in Pipeline: <code>{model_name}__{parameter_name}</code></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter(s):{'svm__C': 1, 'svm__gamma': 1}\n",
      "Best validation score: 0.98\n",
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('svm', SVC())])\n",
    "grid_params = {\n",
    "    'svm__C' : [.01, .1, 1, 10, 100],\n",
    "    'svm__gamma' : [.01, .1, 1, 10, 100]\n",
    "}\n",
    "grid = GridSearchCV(pipe, grid_params, cv = 5)\n",
    "grid.fit(X_train, y_train)\n",
    "print('best parameter(s):{}'.format(grid.best_params_))\n",
    "print('Best validation score: %.2f' % grid.best_score_)\n",
    "print('Test score: %.2f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conveninent Pipeline: <code>make_pipeline</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Test score: 0.94'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "pipe.fit(X_train, y_train)\n",
    "'Test score: %.2f' % pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'note'>The steps are named <u>minmaxscaler</u> and <u>svc</u>. In general, the step names are just lowercase versions of the class names. If multiple steps have the same class, a number is\n",
    "appended:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardscaler-1',\n",
       "  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('pca',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "      svd_solver='auto', tol=0.0, whiten=False)),\n",
       " ('standardscaler-2',\n",
       "  StandardScaler(copy=True, with_mean=True, with_std=True))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Whiten in PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "pipe = make_pipeline(StandardScaler(), PCA(n_components = 2), StandardScaler())\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Step Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class = 'tag'  style = 'text-align: center;'>How do we get the model at the i<sup>th</sup> step?</h2>\n",
    "\n",
    "<p class = 'note'>Solution:<br>\n",
    "     via the <code>named_steps</code> attribute, which is a dictionary\n",
    "from the step names to the estimators: <span class = 'highlight'>\n",
    "    <br>\n",
    "    e.g: <code>pipe.named_steps['pca'].components_</code></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "#get the Principle components:\n",
    "pipe.fit(iris.data)\n",
    "\n",
    "pipe.named_steps['pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654],\n",
       "       [ 0.37741762,  0.92329566,  0.02449161,  0.06694199]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps['pca'].components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Attributes in a Grid-Searched Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('logisticregression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(solver = 'lbfgs'))\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = {'logisticregression__C' : [.001, .01, .1, 1, 10, 100]}\n",
    "grid = GridSearchCV(pipe, grid_params, cv = 5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'note'>we can see that <code>grid.best_estimator_</code> returns a <code>Pipeline</code>.<br>\n",
    "So to access a model we just need to use the attribute <code>named_steps['model_name']</code> as discussed above.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4856842 , -0.40206891, -0.45299539, -0.52024407, -0.25686117,\n",
       "         0.36039283, -0.65009703, -0.97122049,  0.04646819,  0.22464176,\n",
       "        -0.95031614, -0.06044277, -0.51216957, -0.95083589, -0.16133146,\n",
       "         0.69379119,  0.15418147, -0.34888216,  0.30055852,  0.59813117,\n",
       "        -0.86057642, -1.02317914, -0.74783105, -0.83599892, -0.71470772,\n",
       "        -0.05355827, -0.70342769, -0.98714089, -0.71414986, -0.49638629]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the coefficients of Logistic Regression model\n",
    "grid.best_estimator_.named_steps['logisticregression'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-Searching Preprocessing Steps and Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'note'>How do we find out which degree is the best for a Polynomial Regressor on our dataset?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), PolynomialFeatures(), Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'polynomialfeatures__degree' : [1,2,3],\n",
    "    'ridge__alpha' : [.001, .01, .1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, grid_params, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score: 0.84\n",
      "Test score: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print('Best validation score: %.2f' % grid.best_score_)\n",
    "print('Test score: %.2f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polynomialfeatures__degree': 2, 'ridge__alpha': 10}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120287</td>\n",
       "      <td>0.240574</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'polynomialfeatures__degree': 1, 'ridge__alph...</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.712600</td>\n",
       "      <td>0.715702</td>\n",
       "      <td>0.742097</td>\n",
       "      <td>0.774451</td>\n",
       "      <td>0.720458</td>\n",
       "      <td>0.038292</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'polynomialfeatures__degree': 1, 'ridge__alph...</td>\n",
       "      <td>0.658138</td>\n",
       "      <td>0.712605</td>\n",
       "      <td>0.715730</td>\n",
       "      <td>0.742095</td>\n",
       "      <td>0.774446</td>\n",
       "      <td>0.720461</td>\n",
       "      <td>0.038293</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'polynomialfeatures__degree': 1, 'ridge__alph...</td>\n",
       "      <td>0.658028</td>\n",
       "      <td>0.712663</td>\n",
       "      <td>0.716012</td>\n",
       "      <td>0.742069</td>\n",
       "      <td>0.774399</td>\n",
       "      <td>0.720492</td>\n",
       "      <td>0.038303</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'polynomialfeatures__degree': 1, 'ridge__alph...</td>\n",
       "      <td>0.656939</td>\n",
       "      <td>0.713200</td>\n",
       "      <td>0.718712</td>\n",
       "      <td>0.741783</td>\n",
       "      <td>0.773899</td>\n",
       "      <td>0.720767</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'polynomialfeatures__degree': 1, 'ridge__alph...</td>\n",
       "      <td>0.647243</td>\n",
       "      <td>0.715922</td>\n",
       "      <td>0.738234</td>\n",
       "      <td>0.737351</td>\n",
       "      <td>0.767794</td>\n",
       "      <td>0.721186</td>\n",
       "      <td>0.040528</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'polynomialfeatures__degree': 1, 'ridge__alph...</td>\n",
       "      <td>0.600808</td>\n",
       "      <td>0.693489</td>\n",
       "      <td>0.767281</td>\n",
       "      <td>0.691514</td>\n",
       "      <td>0.732633</td>\n",
       "      <td>0.697051</td>\n",
       "      <td>0.055729</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'polynomialfeatures__degree': 2, 'ridge__alph...</td>\n",
       "      <td>0.788582</td>\n",
       "      <td>0.853885</td>\n",
       "      <td>0.766794</td>\n",
       "      <td>0.754234</td>\n",
       "      <td>0.716975</td>\n",
       "      <td>0.776250</td>\n",
       "      <td>0.045272</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'polynomialfeatures__degree': 2, 'ridge__alph...</td>\n",
       "      <td>0.787713</td>\n",
       "      <td>0.854658</td>\n",
       "      <td>0.764083</td>\n",
       "      <td>0.757883</td>\n",
       "      <td>0.720386</td>\n",
       "      <td>0.777094</td>\n",
       "      <td>0.044423</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'polynomialfeatures__degree': 2, 'ridge__alph...</td>\n",
       "      <td>0.785327</td>\n",
       "      <td>0.837162</td>\n",
       "      <td>0.762174</td>\n",
       "      <td>0.800883</td>\n",
       "      <td>0.757079</td>\n",
       "      <td>0.788608</td>\n",
       "      <td>0.029016</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'polynomialfeatures__degree': 2, 'ridge__alph...</td>\n",
       "      <td>0.788432</td>\n",
       "      <td>0.820958</td>\n",
       "      <td>0.781260</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.807368</td>\n",
       "      <td>0.814155</td>\n",
       "      <td>0.032475</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'polynomialfeatures__degree': 2, 'ridge__alph...</td>\n",
       "      <td>0.813006</td>\n",
       "      <td>0.842584</td>\n",
       "      <td>0.846740</td>\n",
       "      <td>0.850704</td>\n",
       "      <td>0.827742</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'polynomialfeatures__degree': 2, 'ridge__alph...</td>\n",
       "      <td>0.787937</td>\n",
       "      <td>0.833650</td>\n",
       "      <td>0.881418</td>\n",
       "      <td>0.768232</td>\n",
       "      <td>0.785143</td>\n",
       "      <td>0.811345</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.049615</td>\n",
       "      <td>0.063578</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'polynomialfeatures__degree': 3, 'ridge__alph...</td>\n",
       "      <td>-11.987543</td>\n",
       "      <td>-4.662055</td>\n",
       "      <td>-3.195039</td>\n",
       "      <td>-11.699121</td>\n",
       "      <td>-7.832383</td>\n",
       "      <td>-7.875341</td>\n",
       "      <td>3.575808</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'polynomialfeatures__degree': 3, 'ridge__alph...</td>\n",
       "      <td>-5.288853</td>\n",
       "      <td>-0.440560</td>\n",
       "      <td>-0.185113</td>\n",
       "      <td>-2.887850</td>\n",
       "      <td>-3.441059</td>\n",
       "      <td>-2.446068</td>\n",
       "      <td>1.920212</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'polynomialfeatures__degree': 3, 'ridge__alph...</td>\n",
       "      <td>-0.086334</td>\n",
       "      <td>0.216420</td>\n",
       "      <td>0.476940</td>\n",
       "      <td>-1.803509</td>\n",
       "      <td>-0.549262</td>\n",
       "      <td>-0.348621</td>\n",
       "      <td>0.804308</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'polynomialfeatures__degree': 3, 'ridge__alph...</td>\n",
       "      <td>0.368887</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.780362</td>\n",
       "      <td>-0.245995</td>\n",
       "      <td>0.674438</td>\n",
       "      <td>0.419979</td>\n",
       "      <td>0.361322</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'polynomialfeatures__degree': 3, 'ridge__alph...</td>\n",
       "      <td>0.476680</td>\n",
       "      <td>0.804296</td>\n",
       "      <td>0.855643</td>\n",
       "      <td>0.604461</td>\n",
       "      <td>0.672404</td>\n",
       "      <td>0.682724</td>\n",
       "      <td>0.136829</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'polynomialfeatures__degree': 3, 'ridge__alph...</td>\n",
       "      <td>0.755615</td>\n",
       "      <td>0.873583</td>\n",
       "      <td>0.853855</td>\n",
       "      <td>0.722748</td>\n",
       "      <td>0.798137</td>\n",
       "      <td>0.800795</td>\n",
       "      <td>0.057089</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.120287      0.240574         0.006241        0.012482   \n",
       "1        0.003124      0.006249         0.000000        0.000000   \n",
       "2        0.000000      0.000000         0.000000        0.000000   \n",
       "3        0.000000      0.000000         0.000000        0.000000   \n",
       "4        0.000000      0.000000         0.003124        0.006248   \n",
       "5        0.000000      0.000000         0.003124        0.006248   \n",
       "6        0.003125      0.006250         0.000000        0.000000   \n",
       "7        0.003124      0.006248         0.000000        0.000000   \n",
       "8        0.003124      0.006248         0.000000        0.000000   \n",
       "9        0.003125      0.006249         0.003124        0.006249   \n",
       "10       0.003124      0.006248         0.000000        0.000000   \n",
       "11       0.000000      0.000000         0.003124        0.006249   \n",
       "12       0.049615      0.063578         0.011346        0.006075   \n",
       "13       0.012497      0.006248         0.000000        0.000000   \n",
       "14       0.008342      0.010740         0.007644        0.006994   \n",
       "15       0.003990      0.004927         0.010973        0.005830   \n",
       "16       0.009373      0.007653         0.006248        0.007653   \n",
       "17       0.012499      0.006249         0.000000        0.000000   \n",
       "\n",
       "   param_polynomialfeatures__degree param_ridge__alpha  \\\n",
       "0                                 1              0.001   \n",
       "1                                 1               0.01   \n",
       "2                                 1                0.1   \n",
       "3                                 1                  1   \n",
       "4                                 1                 10   \n",
       "5                                 1                100   \n",
       "6                                 2              0.001   \n",
       "7                                 2               0.01   \n",
       "8                                 2                0.1   \n",
       "9                                 2                  1   \n",
       "10                                2                 10   \n",
       "11                                2                100   \n",
       "12                                3              0.001   \n",
       "13                                3               0.01   \n",
       "14                                3                0.1   \n",
       "15                                3                  1   \n",
       "16                                3                 10   \n",
       "17                                3                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'polynomialfeatures__degree': 1, 'ridge__alph...           0.658149   \n",
       "1   {'polynomialfeatures__degree': 1, 'ridge__alph...           0.658138   \n",
       "2   {'polynomialfeatures__degree': 1, 'ridge__alph...           0.658028   \n",
       "3   {'polynomialfeatures__degree': 1, 'ridge__alph...           0.656939   \n",
       "4   {'polynomialfeatures__degree': 1, 'ridge__alph...           0.647243   \n",
       "5   {'polynomialfeatures__degree': 1, 'ridge__alph...           0.600808   \n",
       "6   {'polynomialfeatures__degree': 2, 'ridge__alph...           0.788582   \n",
       "7   {'polynomialfeatures__degree': 2, 'ridge__alph...           0.787713   \n",
       "8   {'polynomialfeatures__degree': 2, 'ridge__alph...           0.785327   \n",
       "9   {'polynomialfeatures__degree': 2, 'ridge__alph...           0.788432   \n",
       "10  {'polynomialfeatures__degree': 2, 'ridge__alph...           0.813006   \n",
       "11  {'polynomialfeatures__degree': 2, 'ridge__alph...           0.787937   \n",
       "12  {'polynomialfeatures__degree': 3, 'ridge__alph...         -11.987543   \n",
       "13  {'polynomialfeatures__degree': 3, 'ridge__alph...          -5.288853   \n",
       "14  {'polynomialfeatures__degree': 3, 'ridge__alph...          -0.086334   \n",
       "15  {'polynomialfeatures__degree': 3, 'ridge__alph...           0.368887   \n",
       "16  {'polynomialfeatures__degree': 3, 'ridge__alph...           0.476680   \n",
       "17  {'polynomialfeatures__degree': 3, 'ridge__alph...           0.755615   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.712600           0.715702           0.742097   \n",
       "1            0.712605           0.715730           0.742095   \n",
       "2            0.712663           0.716012           0.742069   \n",
       "3            0.713200           0.718712           0.741783   \n",
       "4            0.715922           0.738234           0.737351   \n",
       "5            0.693489           0.767281           0.691514   \n",
       "6            0.853885           0.766794           0.754234   \n",
       "7            0.854658           0.764083           0.757883   \n",
       "8            0.837162           0.762174           0.800883   \n",
       "9            0.820958           0.781260           0.872669   \n",
       "10           0.842584           0.846740           0.850704   \n",
       "11           0.833650           0.881418           0.768232   \n",
       "12          -4.662055          -3.195039         -11.699121   \n",
       "13          -0.440560          -0.185113          -2.887850   \n",
       "14           0.216420           0.476940          -1.803509   \n",
       "15           0.525549           0.780362          -0.245995   \n",
       "16           0.804296           0.855643           0.604461   \n",
       "17           0.873583           0.853855           0.722748   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.774451         0.720458        0.038292               12  \n",
       "1            0.774446         0.720461        0.038293               11  \n",
       "2            0.774399         0.720492        0.038303               10  \n",
       "3            0.773899         0.720767        0.038425                9  \n",
       "4            0.767794         0.721186        0.040528                8  \n",
       "5            0.732633         0.697051        0.055729               13  \n",
       "6            0.716975         0.776250        0.045272                7  \n",
       "7            0.720386         0.777094        0.044423                6  \n",
       "8            0.757079         0.788608        0.029016                5  \n",
       "9            0.807368         0.814155        0.032475                2  \n",
       "10           0.827742         0.836177        0.013952                1  \n",
       "11           0.785143         0.811345        0.041266                3  \n",
       "12          -7.832383        -7.875341        3.575808               18  \n",
       "13          -3.441059        -2.446068        1.920212               17  \n",
       "14          -0.549262        -0.348621        0.804308               16  \n",
       "15           0.674438         0.419979        0.361322               15  \n",
       "16           0.672404         0.682724        0.136829               14  \n",
       "17           0.798137         0.800795        0.057089                4  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(grid.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720458</td>\n",
       "      <td>0.720461</td>\n",
       "      <td>0.720492</td>\n",
       "      <td>0.720767</td>\n",
       "      <td>0.721186</td>\n",
       "      <td>0.697051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776250</td>\n",
       "      <td>0.777094</td>\n",
       "      <td>0.788608</td>\n",
       "      <td>0.814155</td>\n",
       "      <td>0.836177</td>\n",
       "      <td>0.811345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.875341</td>\n",
       "      <td>-2.446068</td>\n",
       "      <td>-0.348621</td>\n",
       "      <td>0.419979</td>\n",
       "      <td>0.682724</td>\n",
       "      <td>0.800795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "param_ridge__alpha                 0.001     0.010     0.100     1.000    \\\n",
       "param_polynomialfeatures__degree                                           \n",
       "1                                 0.720458  0.720461  0.720492  0.720767   \n",
       "2                                 0.776250  0.777094  0.788608  0.814155   \n",
       "3                                -7.875341 -2.446068 -0.348621  0.419979   \n",
       "\n",
       "param_ridge__alpha                 10.000    100.000  \n",
       "param_polynomialfeatures__degree                      \n",
       "1                                 0.721186  0.697051  \n",
       "2                                 0.836177  0.811345  \n",
       "3                                 0.682724  0.800795  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot = df.pivot(values = 'mean_test_score', index = 'param_polynomialfeatures__degree', columns = 'param_ridge__alpha')\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x2568fd84d68>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.tools.heatmap(pivot, xticklabels = pivot.columns, yticklabels = pivot.index, xlabel = pivot.columns.name, ylabel = pivot.index.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-Searching Which Model To Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier',  SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = [\n",
    "    {\n",
    "        'classifier' : [SVC()],\n",
    "        'preprocessing' : [StandardScaler(), None]\n",
    "    },\n",
    "    {\n",
    "        'classifier' : [RandomForestClassifier()],\n",
    "        'preprocessing' : [None],\n",
    "        'classifier__max_features' : [1,2,3]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, grid_params, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "     kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "     shrinking=True, tol=0.001, verbose=False),\n",
       " 'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state = 6)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
