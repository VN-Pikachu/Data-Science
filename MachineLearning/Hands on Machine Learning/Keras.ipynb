{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".box {\n",
       "    border: 1px double dodgerblue;\n",
       "    padding: 5px;\n",
       "}\n",
       ".note {\n",
       "    font-size: 20;\n",
       "    color: teal;\n",
       "    font-weight: bold;\n",
       "}\n",
       ".highlight {\n",
       "    color: green;\n",
       "    font-family: verdana;\n",
       "}\n",
       ".tag {\n",
       "    background: red;\n",
       "    color: white;\n",
       "    padding: 3px;\n",
       "}\n",
       ".warning {\n",
       "    background: red;\n",
       "    padding: 12px;\n",
       "    font-size: 24px;\n",
       "    color: white;\n",
       "    text-align: center;\n",
       "    font-family: verdana;\n",
       "}\n",
       ".symbol {\n",
       "    color: white;\n",
       "    background: green;\n",
       "    font-size: 20px;\n",
       "    padding: 2px;\n",
       "}\n",
       "code {\n",
       "    font-weight: bold;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run convention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flattenatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 12us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 58s 2us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 17us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 23s 5us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    " \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4,10, subplot_kw = {'xticks':[], 'yticks':[]}, figsize = (12,8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = X_train[i]\n",
    "    ax.imshow(img, cmap = 'binary')\n",
    "    ax.set_title(class_names[y_train[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a validation set and normalize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train[5000:] / 250.0, X_train[:5000] / 250.0\n",
    "y_train, y_valid = y_train[5000:], y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape = (28, 28)),\n",
    "    Dense(300, activation = 'relu'),\n",
    "    Dense(100, activation = 'relu'),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'note'>Summary: <code>model.summary()</code></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class = 'note'>Accessing layers:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Flatten at 0x144fe88a9b0>,\n",
       " <keras.layers.core.Dense at 0x144fe87f198>,\n",
       " <keras.layers.core.Dense at 0x144fe870e48>,\n",
       " <keras.layers.core.Dense at 0x144fe841198>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the $1^{th}$ layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_1').name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class = 'note'>Accessing parameters of a layer</span>: <code>layer.get_weights()</code>, <code>layer.set_weights</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.02569865,  0.05061233, -0.06582257, ...,  0.00753827,\n",
       "         -0.07132196,  0.0394649 ],\n",
       "        [-0.05455979,  0.01142406, -0.06412174, ..., -0.04684324,\n",
       "          0.01373873, -0.05198498],\n",
       "        [-0.06434312,  0.00607312,  0.01144597, ..., -0.02505193,\n",
       "         -0.00737423, -0.00625651],\n",
       "        ...,\n",
       "        [ 0.07101864, -0.05687661, -0.02971516, ..., -0.04701255,\n",
       "         -0.02443425,  0.02400444],\n",
       "        [-0.02934994, -0.03966741,  0.03537916, ...,  0.05634269,\n",
       "         -0.02198635,  0.00107539],\n",
       "        [ 0.06990395,  0.04405352, -0.00909787, ..., -0.02412325,\n",
       "         -0.03614224, -0.06178861]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, bias = model.layers[1].get_weights()\n",
    "(weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 300), (300,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class = 'note'>Compile:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 7s 130us/step - loss: 0.1559 - accuracy: 0.9398 - val_loss: 0.3416 - val_accuracy: 0.8992\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.1541 - accuracy: 0.9409 - val_loss: 0.3671 - val_accuracy: 0.8984\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 0.1502 - accuracy: 0.9434 - val_loss: 0.3571 - val_accuracy: 0.8996\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.1464 - accuracy: 0.9439 - val_loss: 0.4035 - val_accuracy: 0.8978\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 0.1436 - accuracy: 0.9450 - val_loss: 0.3900 - val_accuracy: 0.8974\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 0.1399 - accuracy: 0.9455 - val_loss: 0.3911 - val_accuracy: 0.9018\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.1348 - accuracy: 0.9480 - val_loss: 0.3728 - val_accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.1321 - accuracy: 0.9490 - val_loss: 0.4055 - val_accuracy: 0.9020\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 7s 132us/step - loss: 0.1307 - accuracy: 0.9497 - val_loss: 0.3716 - val_accuracy: 0.9002\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 0.1298 - accuracy: 0.9507 - val_loss: 0.4272 - val_accuracy: 0.9002\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 10, batch_size = 32, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of passing a validation set using the <code>validation_data</code>\n",
    "argument, you could instead set <code>validation_split</code> to the ratio of\n",
    "the training set that you want Keras to use for validation (e.g., 0.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training set was very skewed, with some classes being overrepresented and others underrepresented, it would be useful to set the class_weight argument when\n",
    "calling the <code>fit()</code> method, giving a larger weight to underrepresented classes, and a\n",
    "lower weight to overrepresented classes via <code>class_weights</code>. These weights would be used by Keras when\n",
    "computing the loss. If you need per-instance weights instead, you can set the <code>sample_weight</code> argument (it supersedes class_weight). This could be useful for exam\n",
    "ple if some instances were labeled by experts while others were labeled using a\n",
    "crowdsourcing platform: you might want to give more weight to the former. You can\n",
    "also provide sample weights (but not class weights) for the validation set by adding\n",
    "them as a third item in the validation_data tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code>fit()</code> function return a <i>History Object</i>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters: <code>history.params</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 10,\n",
       " 'steps': None,\n",
       " 'samples': 55000,\n",
       " 'verbose': 1,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'accuracy', 'val_loss', 'val_accuracy']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of epochs: <code>history.epoch</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History: <code>history.history</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.34160061304736883,\n",
       "  0.36714490624442697,\n",
       "  0.35711035861074925,\n",
       "  0.4035276462495327,\n",
       "  0.38998866111040115,\n",
       "  0.39112821951918303,\n",
       "  0.3728327217966318,\n",
       "  0.4054881627008319,\n",
       "  0.37164395840913056,\n",
       "  0.4271891325108707],\n",
       " 'val_accuracy': [0.8992000222206116,\n",
       "  0.8984000086784363,\n",
       "  0.8996000289916992,\n",
       "  0.8978000283241272,\n",
       "  0.8974000215530396,\n",
       "  0.9017999768257141,\n",
       "  0.902400016784668,\n",
       "  0.9020000100135803,\n",
       "  0.9002000093460083,\n",
       "  0.9002000093460083],\n",
       " 'loss': [0.15587034335082228,\n",
       "  0.15405424472161314,\n",
       "  0.15021022457480432,\n",
       "  0.1463829749952663,\n",
       "  0.14355610557713291,\n",
       "  0.1399140280772339,\n",
       "  0.1348003952923146,\n",
       "  0.13209827864441004,\n",
       "  0.1306779365429824,\n",
       "  0.1297549643977122],\n",
       " 'accuracy': [0.9398,\n",
       "  0.9408727,\n",
       "  0.9434364,\n",
       "  0.94387275,\n",
       "  0.9450182,\n",
       "  0.9454909,\n",
       "  0.94798183,\n",
       "  0.949,\n",
       "  0.94969094,\n",
       "  0.95067275]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his = history.history\n",
    "his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341601</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.155870</td>\n",
       "      <td>0.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.8984</td>\n",
       "      <td>0.154054</td>\n",
       "      <td>0.940873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357110</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.150210</td>\n",
       "      <td>0.943436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.403528</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.146383</td>\n",
       "      <td>0.943873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.389989</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.143556</td>\n",
       "      <td>0.945018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.139914</td>\n",
       "      <td>0.945491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.372833</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.947982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.405488</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.132098</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.371644</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.130678</td>\n",
       "      <td>0.949691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.427189</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.129755</td>\n",
       "      <td>0.950673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_accuracy      loss  accuracy\n",
       "0  0.341601        0.8992  0.155870  0.939800\n",
       "1  0.367145        0.8984  0.154054  0.940873\n",
       "2  0.357110        0.8996  0.150210  0.943436\n",
       "3  0.403528        0.8978  0.146383  0.943873\n",
       "4  0.389989        0.8974  0.143556  0.945018\n",
       "5  0.391128        0.9018  0.139914  0.945491\n",
       "6  0.372833        0.9024  0.134800  0.947982\n",
       "7  0.405488        0.9020  0.132098  0.949000\n",
       "8  0.371644        0.9002  0.130678  0.949691\n",
       "9  0.427189        0.9002  0.129755  0.950673"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(his)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x144ff4e9160>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 26us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[99.14747347488404, 0.8658999800682068]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "#return (loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction with probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(30, activation = 'relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 3s 246us/step - loss: 482.9987 - val_loss: 11.3775\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 26us/step - loss: 59.8650 - val_loss: 66.6316\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 57.0580 - val_loss: 171.6631\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 74.9410 - val_loss: 97.7466\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: 55.0564 - val_loss: 2.2686\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: 68.8905 - val_loss: 18.7980\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 28us/step - loss: 52.1304 - val_loss: 32.0696\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 52.3867 - val_loss: 1.6674\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 26us/step - loss: 52.3122 - val_loss: 62.4094\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 26us/step - loss: 50.4746 - val_loss: 210.3401\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 47.0843 - val_loss: 33.1514\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 26us/step - loss: 43.3061 - val_loss: 3.7338\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 26us/step - loss: 44.5783 - val_loss: 70.2143\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 52.2523 - val_loss: 2.7791\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 46.9548 - val_loss: 1.8036\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 49.9531 - val_loss: 1.4006\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 25us/step - loss: 43.2935 - val_loss: 10.1932\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 30us/step - loss: 46.1365 - val_loss: 5.7985\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 26us/step - loss: 46.7048 - val_loss: 1.6676\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 28us/step - loss: 42.4981 - val_loss: 33.3193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15a39b520b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.825690868288973"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building complex models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'wideanddeep.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Concatenate, Input\n",
    "from keras.models import Model\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(8,))\n",
    "hidden1 = Dense(30, activation='relu')(input)\n",
    "hidden2 = Dense(10, activation='relu')(hidden1)\n",
    "concat = Concatenate()([input, hidden2])\n",
    "output = Dense(1)(concat)\n",
    "\n",
    "model = Model(inputs = [input], outputs = [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you want to send a subset of the features through the wide path, and a\n",
    "different subset (possibly overlapping) through the deep path (see Figure 10-14)? In\n",
    "this case, one solution is to use multiple inputs. For example, suppose we want to\n",
    "send 5 features through the deep path (features 0 to 4), and 6 features through the\n",
    "wide path (features 2 to 7):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'cali.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = Input(shape = (5,))\n",
    "input_B = Input(shape = (6,))\n",
    "hidden1 = Dense(30, activation = 'relu')(input_B)\n",
    "hidden2 = Dense(10, activation = 'relu')(hidden1)\n",
    "concat = Concatenate()([input_A, hidden2])\n",
    "ouput = Dense(1)(concat)\n",
    "model = Model(inputs = [input_A, input_B], outputs = [ouput])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/15\n",
      "11610/11610 [==============================] - 1s 75us/step - loss: 9456.8365 - val_loss: 290.3773\n",
      "Epoch 2/15\n",
      "11610/11610 [==============================] - 0s 28us/step - loss: 47.8522 - val_loss: 13.2783\n",
      "Epoch 3/15\n",
      "11610/11610 [==============================] - 0s 29us/step - loss: 37.6293 - val_loss: 6.0192\n",
      "Epoch 4/15\n",
      "11610/11610 [==============================] - 0s 29us/step - loss: 34.5328 - val_loss: 4.4234\n",
      "Epoch 5/15\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: 30.4128 - val_loss: 35.2407\n",
      "Epoch 6/15\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: 28.0197 - val_loss: 1.7534\n",
      "Epoch 7/15\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: 32.3908 - val_loss: 2.3072\n",
      "Epoch 8/15\n",
      "11610/11610 [==============================] - 0s 28us/step - loss: 27.6295 - val_loss: 2.1907\n",
      "Epoch 9/15\n",
      "11610/11610 [==============================] - 0s 29us/step - loss: 24.7856 - val_loss: 71.1152\n",
      "Epoch 10/15\n",
      "11610/11610 [==============================] - 0s 29us/step - loss: 25.4190 - val_loss: 106.4459\n",
      "Epoch 11/15\n",
      "11610/11610 [==============================] - 0s 30us/step - loss: 23.2324 - val_loss: 2.9069\n",
      "Epoch 12/15\n",
      "11610/11610 [==============================] - 0s 29us/step - loss: 25.4230 - val_loss: 6.0024\n",
      "Epoch 13/15\n",
      "11610/11610 [==============================] - 0s 29us/step - loss: 25.6465 - val_loss: 1.8445\n",
      "Epoch 14/15\n",
      "11610/11610 [==============================] - 0s 29us/step - loss: 25.9998 - val_loss: 17.8661\n",
      "Epoch 15/15\n",
      "11610/11610 [==============================] - 0s 30us/step - loss: 26.2777 - val_loss: 1.5379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15a3a63d5f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss = 'mse')\n",
    "X_train_new = [X_train[:,:5], X_train[:, 2:]]\n",
    "X_valid_new = [X_valid[:,:5], X_valid[:,2:]]\n",
    "model.fit(X_train_new, y_train, validation_data= (X_valid_new, y_valid), epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 15us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3842270030531771"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new = [X_test[:, :5], X_test[:, 2:]]\n",
    "model.evaluate(X_test_new, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32354093],\n",
       "       [0.74637717],\n",
       "       [1.6174375 ],\n",
       "       ...,\n",
       "       [0.6243967 ],\n",
       "       [2.0308983 ],\n",
       "       [2.4300084 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'multipleoutput.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = Input(shape = (5,))\n",
    "input_B = Input(shape = (6,))\n",
    "hidden1 = Dense(30, activation='relu')(input_B)\n",
    "hidden2 = Dense(10, activation='relu')(hidden1)\n",
    "concat = Concatenate()([input_A, hidden2])\n",
    "output = Dense(1)(concat)\n",
    "aux = Dense(1)(hidden2)\n",
    "model = Model(inputs = [input_A, input_B], outputs = [output, aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each output will need its own loss function, so when we compile the model we\n",
    "should pass a list of losses (if we pass a single loss, Keras will assume that the same\n",
    "loss must be used for all outputs). By default, Keras will compute all these losses and\n",
    "simply add them up to get the final loss used for training. However, we care much\n",
    "more about the main output than about the auxiliary output (as it is just used for reg\n",
    "ularization), so we want to give the main outputs loss a much greater weight. Fortu\n",
    "nately, it is possible to set all the loss weights when compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 37us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 53us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 32us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 33us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 31us/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15a3d0f4e80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mse', loss_weights=[.9, .1], optimizer= 'sgd')\n",
    "\n",
    "model.fit(X_train_new, [y_train, y_train], epochs = 20, validation_data= (X_valid_new, [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan]], dtype=float32),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Restore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "my_model = keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'callback.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>ModelCheckpoint</code>: save the model after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 6)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, random_state = 42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('iris_model.h5', save_best_only=True)\n",
    "model = Sequential([\n",
    "    Dense(15, activation = 'relu', input_shape = (4,)),\n",
    "    Dense(3, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 28 samples\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.7344 - accuracy: 0.7262 - val_loss: 0.6814 - val_accuracy: 0.8571\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.7228 - accuracy: 0.7262 - val_loss: 0.6689 - val_accuracy: 0.8571\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.7118 - accuracy: 0.7381 - val_loss: 0.6570 - val_accuracy: 0.8571\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.7006 - accuracy: 0.7500 - val_loss: 0.6459 - val_accuracy: 0.8571\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.6911 - accuracy: 0.7619 - val_loss: 0.6350 - val_accuracy: 0.8571\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 0s 47us/step - loss: 0.6808 - accuracy: 0.7857 - val_loss: 0.6248 - val_accuracy: 0.8571\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 0s 103us/step - loss: 0.6713 - accuracy: 0.7857 - val_loss: 0.6152 - val_accuracy: 0.8571\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.6624 - accuracy: 0.7976 - val_loss: 0.6061 - val_accuracy: 0.8571\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.6541 - accuracy: 0.7976 - val_loss: 0.5971 - val_accuracy: 0.8571\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.6457 - accuracy: 0.7976 - val_loss: 0.5886 - val_accuracy: 0.8571\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.6379 - accuracy: 0.8214 - val_loss: 0.5805 - val_accuracy: 0.8571\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.6302 - accuracy: 0.8214 - val_loss: 0.5728 - val_accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 0s 119us/step - loss: 0.6228 - accuracy: 0.8095 - val_loss: 0.5653 - val_accuracy: 0.8571\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.6161 - accuracy: 0.8095 - val_loss: 0.5579 - val_accuracy: 0.8571\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.6093 - accuracy: 0.8095 - val_loss: 0.5508 - val_accuracy: 0.8571\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.6026 - accuracy: 0.8095 - val_loss: 0.5438 - val_accuracy: 0.8571\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.5965 - accuracy: 0.7976 - val_loss: 0.5369 - val_accuracy: 0.8571\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 0s 131us/step - loss: 0.5905 - accuracy: 0.7976 - val_loss: 0.5302 - val_accuracy: 0.8571\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.5843 - accuracy: 0.7976 - val_loss: 0.5239 - val_accuracy: 0.8571\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.5787 - accuracy: 0.7976 - val_loss: 0.5177 - val_accuracy: 0.8571\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.5734 - accuracy: 0.7857 - val_loss: 0.5117 - val_accuracy: 0.8571\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5680 - accuracy: 0.8095 - val_loss: 0.5057 - val_accuracy: 0.8571\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.5627 - accuracy: 0.8095 - val_loss: 0.5000 - val_accuracy: 0.8571\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5578 - accuracy: 0.8095 - val_loss: 0.4943 - val_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5531 - accuracy: 0.8095 - val_loss: 0.4888 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.5482 - accuracy: 0.8095 - val_loss: 0.4836 - val_accuracy: 0.8571\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5438 - accuracy: 0.8095 - val_loss: 0.4786 - val_accuracy: 0.8571\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 0s 131us/step - loss: 0.5393 - accuracy: 0.8095 - val_loss: 0.4739 - val_accuracy: 0.8571\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.93 - 0s 59us/step - loss: 0.5350 - accuracy: 0.8095 - val_loss: 0.4691 - val_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5309 - accuracy: 0.8095 - val_loss: 0.4645 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15a40d32eb8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs = 30, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model = keras.models.load_model('iris_model.h5') #roll back to the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 15)                75        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 123\n",
      "Trainable params: 123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "iris_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.08934874,  0.38745114,  0.40277112,  0.2372908 ,  0.41815597,\n",
       "         -0.49217185,  0.06158461,  0.03046875,  0.3097117 , -0.07180721,\n",
       "         -0.54211545,  0.59913695, -0.06765333, -0.39068955, -0.22628614],\n",
       "        [ 0.4489913 ,  0.5769414 , -0.6278987 , -0.15419298, -0.07607377,\n",
       "          0.49272776,  0.14024562,  0.04267786,  0.34417343, -0.19586828,\n",
       "         -0.4353738 ,  0.2352206 ,  0.02731327,  0.05962317,  0.05053587],\n",
       "        [-0.25967586,  0.04085253,  0.3756546 , -0.5693138 , -0.27280077,\n",
       "         -0.39715877,  0.00363374, -0.34438756, -0.21955265, -0.4662081 ,\n",
       "         -0.48411444, -0.11246449, -0.24012765,  0.27570513, -0.30326617],\n",
       "        [-0.02964747, -0.23856936, -0.44467843, -0.25741377,  0.47703767,\n",
       "          0.11917481,  0.67687285, -0.36216867, -0.00733115, -0.55946946,\n",
       "         -0.6349757 , -0.2659748 ,  0.06249695, -0.46005473, -0.19486548]],\n",
       "       dtype=float32),\n",
       " array([ 0.04090235, -0.09318069,  0.11662392, -0.03764937, -0.10250963,\n",
       "         0.10178684,  0.12022529, -0.00925665, -0.09441953,  0.07669336,\n",
       "         0.08174247,  0.04421582, -0.0137636 , -0.09853214, -0.0769448 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to implement early stopping is to simply use the <code>EarlyStopping</code> callback. It will interrupt training when it measures no progress on the validation set for\n",
    "a number of epochs (defined by the <code>patience</code> argument), and it will optionally roll\n",
    "back to the best model. You can combine both callbacks to both save checkpoints of\n",
    "your model (in case your computer crashes), and actually interrupt training early\n",
    "when there is no more progress (to avoid wasting time and resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 28 samples\n",
      "Epoch 1/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5267 - accuracy: 0.8095 - val_loss: 0.4600 - val_accuracy: 0.8571\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5227 - accuracy: 0.8095 - val_loss: 0.4556 - val_accuracy: 0.8571\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5188 - accuracy: 0.8095 - val_loss: 0.4513 - val_accuracy: 0.8929\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.5149 - accuracy: 0.8095 - val_loss: 0.4471 - val_accuracy: 0.8929\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5111 - accuracy: 0.8095 - val_loss: 0.4430 - val_accuracy: 0.8929\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.5075 - accuracy: 0.8095 - val_loss: 0.4389 - val_accuracy: 0.8929\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.5040 - accuracy: 0.8095 - val_loss: 0.4348 - val_accuracy: 0.8929\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.5003 - accuracy: 0.8095 - val_loss: 0.4309 - val_accuracy: 0.8929\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.4969 - accuracy: 0.8214 - val_loss: 0.4268 - val_accuracy: 0.8929\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 0s 364us/step - loss: 0.4935 - accuracy: 0.8214 - val_loss: 0.4230 - val_accuracy: 0.9286\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.4902 - accuracy: 0.8214 - val_loss: 0.4193 - val_accuracy: 0.9286\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.4869 - accuracy: 0.8095 - val_loss: 0.4156 - val_accuracy: 0.9286\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.4838 - accuracy: 0.8095 - val_loss: 0.4121 - val_accuracy: 0.9286\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.4805 - accuracy: 0.8095 - val_loss: 0.4087 - val_accuracy: 0.9286\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 0s 107us/step - loss: 0.4774 - accuracy: 0.8095 - val_loss: 0.4053 - val_accuracy: 0.9286\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.4745 - accuracy: 0.8095 - val_loss: 0.4020 - val_accuracy: 0.9286\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 0s 119us/step - loss: 0.4714 - accuracy: 0.8333 - val_loss: 0.3987 - val_accuracy: 0.9286\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 0s 72us/step - loss: 0.4685 - accuracy: 0.8333 - val_loss: 0.3955 - val_accuracy: 0.9286\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.4656 - accuracy: 0.8333 - val_loss: 0.3923 - val_accuracy: 0.9643\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.4628 - accuracy: 0.8333 - val_loss: 0.3891 - val_accuracy: 0.9643\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.4599 - accuracy: 0.8333 - val_loss: 0.3859 - val_accuracy: 0.9643\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 0s 60us/step - loss: 0.4572 - accuracy: 0.8333 - val_loss: 0.3827 - val_accuracy: 0.9643\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.4545 - accuracy: 0.8333 - val_loss: 0.3796 - val_accuracy: 0.9643\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.4519 - accuracy: 0.8333 - val_loss: 0.3767 - val_accuracy: 0.9643\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.4494 - accuracy: 0.8333 - val_loss: 0.3740 - val_accuracy: 0.9643\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.4467 - accuracy: 0.8333 - val_loss: 0.3713 - val_accuracy: 0.9643\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.4441 - accuracy: 0.8452 - val_loss: 0.3689 - val_accuracy: 0.9643\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.4418 - accuracy: 0.8452 - val_loss: 0.3665 - val_accuracy: 0.9643\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.4393 - accuracy: 0.8452 - val_loss: 0.3639 - val_accuracy: 0.9643\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 0s 107us/step - loss: 0.4369 - accuracy: 0.8452 - val_loss: 0.3613 - val_accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15a41f961d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "checkpoint_cb = ModelCheckpoint('iris_early.h5', save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 30, validation_data=(X_valid, y_valid), callbacks = [early_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'highlight'>The number of epochs can be set to a large value since training will stop automatically when there is no more progress. Moreover, there is no need to restore the best\n",
    "model saved in this case since the <code>EarlyStopping</code> callback will keep track of the best\n",
    "weights and restore them for us at the end of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2019_11_13-18_03_33'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_01_16-11_28_43'\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tensorboard_cb = TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 28 samples\n",
      "Epoch 1/20\n",
      "84/84 [==============================] - 1s 11ms/step - loss: 0.3914 - accuracy: 0.8571 - val_loss: 0.3127 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.223345). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "84/84 [==============================] - 0s 131us/step - loss: 0.3895 - accuracy: 0.8571 - val_loss: 0.3104 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 0s 278us/step - loss: 0.3875 - accuracy: 0.8571 - val_loss: 0.3083 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 0s 279us/step - loss: 0.3857 - accuracy: 0.8571 - val_loss: 0.3062 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 0s 289us/step - loss: 0.3838 - accuracy: 0.8571 - val_loss: 0.3043 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 0s 185us/step - loss: 0.3819 - accuracy: 0.8571 - val_loss: 0.3023 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.3801 - accuracy: 0.8571 - val_loss: 0.3003 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 0s 91us/step - loss: 0.3783 - accuracy: 0.8571 - val_loss: 0.2985 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 0s 107us/step - loss: 0.3764 - accuracy: 0.8571 - val_loss: 0.2966 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 0s 495us/step - loss: 0.3746 - accuracy: 0.8571 - val_loss: 0.2947 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 0s 353us/step - loss: 0.3729 - accuracy: 0.8571 - val_loss: 0.2927 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 0s 176us/step - loss: 0.3710 - accuracy: 0.8571 - val_loss: 0.2910 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.3694 - accuracy: 0.8690 - val_loss: 0.2894 - val_accuracy: 0.9643\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 0s 58us/step - loss: 0.3676 - accuracy: 0.8690 - val_loss: 0.2877 - val_accuracy: 0.9643\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.3658 - accuracy: 0.8690 - val_loss: 0.2858 - val_accuracy: 0.9643\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 0s 95us/step - loss: 0.3641 - accuracy: 0.8690 - val_loss: 0.2841 - val_accuracy: 0.9643\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 0s 448us/step - loss: 0.3624 - accuracy: 0.8690 - val_loss: 0.2825 - val_accuracy: 0.9643\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 0s 59us/step - loss: 0.3607 - accuracy: 0.8690 - val_loss: 0.2807 - val_accuracy: 0.9643\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 0s 83us/step - loss: 0.3591 - accuracy: 0.8810 - val_loss: 0.2791 - val_accuracy: 0.9643\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 0s 71us/step - loss: 0.3575 - accuracy: 0.8810 - val_loss: 0.2773 - val_accuracy: 0.9643\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs = 20, callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Neurons per Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a large number to overfit, then shrink until it does not overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate, Batch Size and Other Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'tuning.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a func\n",
    "tion that will build and compile a Keras model, given a set of hyperparameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def build_model(n_hidden = 1, units = 30, learning_rate = .001, input_shape = (8,)):\n",
    "    model = Sequential()\n",
    "    for _ in range(n_hidden):\n",
    "        option = {'input_shape' : input_shape} if _ else {}\n",
    "        layer = Dense(units, activation = 'relu', **option)\n",
    "        model.add(layer)\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = 'mse', optimizer = SGD(learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "model = KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 301us/step - loss: 495.6952 - val_loss: 199.5927\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 123.5519 - val_loss: 64.4282\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 45.8952 - val_loss: 25.4820\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 26.7146 - val_loss: 17.3246\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.5800 - val_loss: 19.9232\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.4593 - val_loss: 14.3066\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.7112 - val_loss: 14.2563\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.0939 - val_loss: 12.0039\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.7254 - val_loss: 12.2816\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.9019 - val_loss: 11.6429\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.0195 - val_loss: 10.8662\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 12.3466 - val_loss: 12.6121\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 12.1243 - val_loss: 13.7170\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 11.9400 - val_loss: 10.7883\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 11.0493 - val_loss: 11.8004\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.5333 - val_loss: 12.3275\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.6249 - val_loss: 10.2887\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.6982 - val_loss: 11.2532\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 10.0825 - val_loss: 10.6202\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 9.0919 - val_loss: 10.3004\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 8.9318 - val_loss: 12.6742\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.2494 - val_loss: 10.2902\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 8.3499 - val_loss: 15.9662\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.2334 - val_loss: 15.9947\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 8.5603 - val_loss: 10.9485\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 7.5751 - val_loss: 13.5201\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 8.3666 - val_loss: 12.5857\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 283us/step - loss: 546.7733 - val_loss: 232.1459\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 154.8432 - val_loss: 42.7721\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 46.9541 - val_loss: 21.7984\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 31.6282 - val_loss: 20.4051\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 30.0481 - val_loss: 16.8144\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 27.0418 - val_loss: 16.4176\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 25.0912 - val_loss: 57.2153\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 31.2078 - val_loss: 13.9936\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 21.8852 - val_loss: 14.9013\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 19.6758 - val_loss: 25.5574\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 21.9389 - val_loss: 17.9281\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 19.0439 - val_loss: 12.5825\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 17.8439 - val_loss: 12.0231\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 16.1912 - val_loss: 65.3057\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 23.2784 - val_loss: 15.1238\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.1532 - val_loss: 17.5850\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 16.3049 - val_loss: 12.7726\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.4929 - val_loss: 11.8990\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.4345 - val_loss: 12.2829\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.2045 - val_loss: 15.2205\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 14.0041 - val_loss: 12.0360\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 13.2156 - val_loss: 11.9353\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 12.8918 - val_loss: 18.7924\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 14.4925 - val_loss: 12.2726\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 12.2779 - val_loss: 11.5651\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 12.1875 - val_loss: 11.1601\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.9186 - val_loss: 11.1047\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 88us/step - loss: 11.6192 - val_loss: 11.0016\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.7949 - val_loss: 11.7128\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.2335 - val_loss: 37.8919\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.8895 - val_loss: 12.2350\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.3091 - val_loss: 22.4102\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 21.3131 - val_loss: 20.0317\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 12.6482 - val_loss: 13.2006\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.0636 - val_loss: 19.7030\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.2524 - val_loss: 12.6308\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 11.8354 - val_loss: 18.1802\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.2211 - val_loss: 12.6223\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 255us/step - loss: 522.0900 - val_loss: 251.1391\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 150.2501 - val_loss: 52.3648\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 47.7245 - val_loss: 28.0251\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 30.1586 - val_loss: 19.7337\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 24.1822 - val_loss: 24.5105\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 22.6044 - val_loss: 14.4687\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.8828 - val_loss: 33.5847\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 24.8838 - val_loss: 19.4078\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 18.9983 - val_loss: 15.9874\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.0898 - val_loss: 15.7380\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.2102 - val_loss: 13.3701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.5864 - val_loss: 15.6081\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.0491 - val_loss: 13.3094\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.5871 - val_loss: 14.2843\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.0191 - val_loss: 17.9082\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.0365 - val_loss: 47.9168\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.2498 - val_loss: 16.8949\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.4848 - val_loss: 107.5639\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 26.3742 - val_loss: 22.1817\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.4194 - val_loss: 16.1575\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.7339 - val_loss: 14.2312\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.0740 - val_loss: 15.2075\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.2564 - val_loss: 13.8419\n",
      "57/57 [==============================] - 0s 53us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 259us/step - loss: 597.5095 - val_loss: 296.9117\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 193.3117 - val_loss: 44.3094\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 49.3529 - val_loss: 22.7081\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 32.3957 - val_loss: 22.4485\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 28.2122 - val_loss: 24.1097\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 27.4406 - val_loss: 15.2500\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.6349 - val_loss: 14.1629\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.1472 - val_loss: 14.0545\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.9188 - val_loss: 16.2088\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 19.2450 - val_loss: 19.5718\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.1956 - val_loss: 14.1416\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.5389 - val_loss: 67.4119\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 26.4144 - val_loss: 19.2670\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.2052 - val_loss: 13.7696\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.4441 - val_loss: 14.3086\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.3752 - val_loss: 14.9677\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.1800 - val_loss: 13.1901\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.6531 - val_loss: 20.6522\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.7297 - val_loss: 15.0305\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.1599 - val_loss: 17.8251\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.1936 - val_loss: 18.7869\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.0773 - val_loss: 12.5179\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.4850 - val_loss: 12.7207\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.9407 - val_loss: 105.0167\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 21.1631 - val_loss: 12.6892\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.6840 - val_loss: 13.5835\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 12.9425 - val_loss: 12.5321\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.2386 - val_loss: 12.3338\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.4284 - val_loss: 13.1304\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.6902 - val_loss: 11.9036\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.6895 - val_loss: 17.0094\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.1127 - val_loss: 11.6141\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.4396 - val_loss: 12.1028\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.6894 - val_loss: 13.3021\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.5182 - val_loss: 15.0582\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.4612 - val_loss: 11.8584\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.8739 - val_loss: 99.0761\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.2606 - val_loss: 13.4230\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.9866 - val_loss: 13.0261\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.0685 - val_loss: 38.4627\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.7519 - val_loss: 15.6766\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.3876 - val_loss: 12.3093\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 254us/step - loss: 510.0080 - val_loss: 227.6044\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 121.9338 - val_loss: 30.0000\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 33.7520 - val_loss: 21.2168\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 27.0406 - val_loss: 17.0108\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 24.3200 - val_loss: 14.6475\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 22.4911 - val_loss: 13.7106\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 20.6578 - val_loss: 13.9541\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 19.5839 - val_loss: 12.7275\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 40us/step - loss: 18.8439 - val_loss: 16.0882\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 19.0651 - val_loss: 13.3238\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 18.4195 - val_loss: 11.8446\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 17.1363 - val_loss: 12.7547\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 16.4857 - val_loss: 11.6995\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 15.6470 - val_loss: 11.2330\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 16.0980 - val_loss: 11.5048\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.1739 - val_loss: 10.8192\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.2652 - val_loss: 12.3207\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 14.6408 - val_loss: 25.9679\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 18.6125 - val_loss: 15.9239\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.4122 - val_loss: 16.7790\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 14.7822 - val_loss: 13.5131\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 13.4621 - val_loss: 13.4309\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 48us/step - loss: 13.4083 - val_loss: 12.7161\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 12.9663 - val_loss: 10.7371\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 13.2751 - val_loss: 10.8785\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.6285 - val_loss: 17.9574\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 14.6426 - val_loss: 12.9464\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.7794 - val_loss: 10.8195\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.2428 - val_loss: 11.1169\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.9323 - val_loss: 11.1994\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.2398 - val_loss: 10.5005\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.3764 - val_loss: 12.1374\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 11.9382 - val_loss: 13.3915\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.8031 - val_loss: 10.6919\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.6132 - val_loss: 11.2993\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.3774 - val_loss: 10.5823\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 11.4469 - val_loss: 26.3054\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 19.2747 - val_loss: 13.6725\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.8656 - val_loss: 12.1304\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.3322 - val_loss: 11.2497\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.0545 - val_loss: 11.9899\n",
      "56/56 [==============================] - 0s 36us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 325us/step - loss: 471.8701 - val_loss: 537.5009\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 596.0952 - val_loss: 414.9927\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 335.0302 - val_loss: 418.2340\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 297.6335 - val_loss: 75.1771\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 47.2694 - val_loss: 25.7908\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.0320 - val_loss: 21.9292\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 15.9291 - val_loss: 53.9621\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 19.2034 - val_loss: 12.9728\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 10.4446 - val_loss: 19.9453\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 13.4244 - val_loss: 25.7404\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.0090 - val_loss: 13.9877\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.1842 - val_loss: 68.4607\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 25.4348 - val_loss: 29.5122\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.1678 - val_loss: 13.3346\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 8.9511 - val_loss: 15.5724\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 8.6470 - val_loss: 11.7920\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 7.5719 - val_loss: 18.9869\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.2387 - val_loss: 10.8014\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 7.9434 - val_loss: 13.1178\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 7.1449 - val_loss: 13.9967\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 7.9628 - val_loss: 10.7992\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 6.1863 - val_loss: 14.4408\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 7.6126 - val_loss: 46.1248\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.4779 - val_loss: 13.6667\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 6.4513 - val_loss: 14.9345\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 6.4746 - val_loss: 11.0214\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 5.4970 - val_loss: 37.5049\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 20.1659 - val_loss: 24.7072\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.0757 - val_loss: 14.8481\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 7.0057 - val_loss: 10.7173\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 5.5516 - val_loss: 11.8526\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 7.2496 - val_loss: 21.9547\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 8.2633 - val_loss: 11.7747\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 5.0949 - val_loss: 12.3921\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.3238 - val_loss: 17.3330\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 5.7214 - val_loss: 12.8236\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 6.6162 - val_loss: 12.6231\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 4.6505 - val_loss: 15.8051\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 6.9396 - val_loss: 17.7982\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 5.8775 - val_loss: 11.2471\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 308us/step - loss: 413.4065 - val_loss: 46.5783\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 38.6321 - val_loss: 68.6001\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 36.2054 - val_loss: 18.0070\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 34.1281 - val_loss: 340.8990\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 151.6099 - val_loss: 59.5887\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 43.0131 - val_loss: 16.3217\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.1703 - val_loss: 197.7034\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 65.9727 - val_loss: 25.1556\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 36.0473 - val_loss: 19.5845\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 16.5576 - val_loss: 29.5780\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 32.9181 - val_loss: 14.9009\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.9169 - val_loss: 11.5432\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 16.3541 - val_loss: 33.5946\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 25.8653 - val_loss: 12.6030\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 15.4709 - val_loss: 36.2706\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 19.9258 - val_loss: 10.4619\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.2894 - val_loss: 10.5999\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 62us/step - loss: 12.9256 - val_loss: 16.9145\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 15.6243 - val_loss: 15.5530\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 11.5471 - val_loss: 22.7653\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 14.6242 - val_loss: 10.7417\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 12.0825 - val_loss: 267.9808\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 66.6614 - val_loss: 22.4040\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 22.6695 - val_loss: 12.5460\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.9516 - val_loss: 18.9869\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.8527 - val_loss: 14.3031\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 277us/step - loss: 463.6466 - val_loss: 68.2866\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 90.7127 - val_loss: 53.8625\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 57.5506 - val_loss: 42.0667\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 45.8403 - val_loss: 444.0481\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 469.7934 - val_loss: 111.8246\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 97.6794 - val_loss: 20.1974\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 29.2607 - val_loss: 34.0124\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 42.5534 - val_loss: 31.7469\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 22.2477 - val_loss: 26.7618\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 20.4785 - val_loss: 15.0325\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 22.5518 - val_loss: 192.1778\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 121.5702 - val_loss: 19.4995\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 26.2164 - val_loss: 13.7931\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 16.2799 - val_loss: 112.3544\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 37.2986 - val_loss: 17.7055\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 17.7578 - val_loss: 11.1923\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 11.8610 - val_loss: 15.8438\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.2413 - val_loss: 10.3880\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.6635 - val_loss: 14.1577\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 13.9177 - val_loss: 17.8442\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.9327 - val_loss: 71.7575\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 38.5326 - val_loss: 18.2622\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.3688 - val_loss: 16.9499\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 15.6445 - val_loss: 52.1886\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 21.1723 - val_loss: 13.8411\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 10.2217 - val_loss: 11.5997\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.3246 - val_loss: 11.9418\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 11.4827 - val_loss: 36.5906\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 290us/step - loss: 459.7563 - val_loss: 89.3578\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 58.7337 - val_loss: 20.8761\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 27.4476 - val_loss: 42.3605\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 38.7957 - val_loss: 16.2912\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 35.1737 - val_loss: 119.1152\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 114.5079 - val_loss: 80.7992\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 30.7469 - val_loss: 95.4644\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 56.2671 - val_loss: 38.4026\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 21.3821 - val_loss: 18.0595\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 24.7244 - val_loss: 15.7300\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.9954 - val_loss: 15.8200\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.3321 - val_loss: 12.9875\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 16.2067 - val_loss: 14.5917\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 27.4113 - val_loss: 12.7723\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.6013 - val_loss: 36.6552\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 18.9389 - val_loss: 13.9006\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.6514 - val_loss: 80.3504\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 20.7244 - val_loss: 14.5169\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 22.7800 - val_loss: 37.3732\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.0433 - val_loss: 18.7357\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 25.5966 - val_loss: 13.3494\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 12.5067 - val_loss: 125.3268\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 33.9586 - val_loss: 14.6815\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.9334 - val_loss: 16.1875\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 306us/step - loss: 427.0328 - val_loss: 441.0390\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 353.1574 - val_loss: 146.7319\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 69.2469 - val_loss: 20.6086\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 66us/step - loss: 39.8245 - val_loss: 12.0981\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 70us/step - loss: 24.5545 - val_loss: 24.1416\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 25.6562 - val_loss: 23.6601\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 33.9830 - val_loss: 31.3300\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 23.4920 - val_loss: 11.0637\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 29.9277 - val_loss: 31.7215\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 24.2686 - val_loss: 26.3217\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 66us/step - loss: 16.4218 - val_loss: 35.0928\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 30.2241 - val_loss: 17.0889\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 16.1768 - val_loss: 100.6356\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 55.1813 - val_loss: 179.4373\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 65us/step - loss: 55.9284 - val_loss: 19.9452\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 25.4431 - val_loss: 11.3794\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 66us/step - loss: 12.6967 - val_loss: 12.4745\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 15.8916 - val_loss: 10.7274\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 13.6550 - val_loss: 15.8347\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 12.2203 - val_loss: 14.8152\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 13.2950 - val_loss: 11.7012\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 17.3622 - val_loss: 12.8217\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 66us/step - loss: 9.9985 - val_loss: 13.1137\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 20.8347 - val_loss: 56.0777\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 20.6691 - val_loss: 12.1951\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 9.5200 - val_loss: 46.3678\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 20.1872 - val_loss: 15.2756\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 9.4214 - val_loss: 44.8605\n",
      "56/56 [==============================] - 0s 53us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 426us/step - loss: 560.6335 - val_loss: 438.4075\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 387.4604 - val_loss: 120.2296\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 76.2883 - val_loss: 39.8598\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 38.3804 - val_loss: 63.3266\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 75us/step - loss: 35.2539 - val_loss: 23.5035\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 75us/step - loss: 23.5545 - val_loss: 17.2610\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 79us/step - loss: 19.9135 - val_loss: 24.0678\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 84us/step - loss: 18.7632 - val_loss: 15.6390\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 79us/step - loss: 17.4385 - val_loss: 18.8815\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 79us/step - loss: 16.6176 - val_loss: 17.2795\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 14.4004 - val_loss: 13.2683\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 83us/step - loss: 13.4174 - val_loss: 13.0789\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 83us/step - loss: 13.0747 - val_loss: 15.0480\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 75us/step - loss: 12.8237 - val_loss: 18.1085\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 75us/step - loss: 13.5317 - val_loss: 12.0502\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 11.5757 - val_loss: 12.6527\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 11.1305 - val_loss: 12.6875\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 10.6371 - val_loss: 17.1225\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 10.9642 - val_loss: 35.8524\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 15.2530 - val_loss: 11.6979\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.9750 - val_loss: 12.7715\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.9627 - val_loss: 13.0619\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 9.4658 - val_loss: 15.8947\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.8201 - val_loss: 29.2781\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.9555 - val_loss: 13.9492\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.0698 - val_loss: 11.2337\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.0548 - val_loss: 15.6483\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.6838 - val_loss: 11.4406\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.1325 - val_loss: 11.9239\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.1939 - val_loss: 14.5428\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.1371 - val_loss: 11.3065\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.7145 - val_loss: 11.4273\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 8.1506 - val_loss: 13.7084\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 7.9960 - val_loss: 11.6401\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.7725 - val_loss: 12.0593\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 7.6661 - val_loss: 15.1113\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 362us/step - loss: 601.6871 - val_loss: 447.1411\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 458.7532 - val_loss: 98.2188\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 76.7443 - val_loss: 50.8450\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 42.2831 - val_loss: 21.5257\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 31.9043 - val_loss: 17.3418\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 28.5117 - val_loss: 15.0782\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 24.4834 - val_loss: 34.2906\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 31.4182 - val_loss: 13.2658\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.8493 - val_loss: 13.7502\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.4420 - val_loss: 11.8429\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.9357 - val_loss: 19.6351\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 21.1381 - val_loss: 11.6009\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.7586 - val_loss: 34.7512\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 25.7636 - val_loss: 12.4573\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.9551 - val_loss: 30.1906\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 17.2968 - val_loss: 14.9662\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.9055 - val_loss: 17.8045\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.6210 - val_loss: 22.8558\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.7135 - val_loss: 29.7826\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.0218 - val_loss: 21.4893\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.0584 - val_loss: 10.2731\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.9375 - val_loss: 12.2961\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.5659 - val_loss: 11.1829\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.1571 - val_loss: 11.3616\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 11.2431 - val_loss: 12.9564\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.2802 - val_loss: 10.5534\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 53us/step - loss: 11.0511 - val_loss: 10.4278\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.7612 - val_loss: 11.4031\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.5478 - val_loss: 10.9070\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.5046 - val_loss: 17.1678\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.1606 - val_loss: 11.3047\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 346us/step - loss: 598.8175 - val_loss: 469.1539\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 511.8946 - val_loss: 281.2594\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 157.7760 - val_loss: 84.5925\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 57.1201 - val_loss: 20.3085\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 36.1601 - val_loss: 31.0578\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 32.1761 - val_loss: 14.6235\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 27.1886 - val_loss: 14.6732\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 24.0150 - val_loss: 13.2477\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.6518 - val_loss: 12.2104\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.3599 - val_loss: 12.6926\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.4333 - val_loss: 12.3064\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.9033 - val_loss: 19.3464\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.8145 - val_loss: 12.8162\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.9742 - val_loss: 17.7978\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.0373 - val_loss: 12.7931\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.9289 - val_loss: 93.2748\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 24.8622 - val_loss: 13.5147\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.8164 - val_loss: 17.1476\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.6169 - val_loss: 14.5944\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 383us/step - loss: 634.2146 - val_loss: 473.6358\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 555.1130 - val_loss: 315.0521\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 226.5683 - val_loss: 65.3628\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 76.5457 - val_loss: 35.4308\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 38.4901 - val_loss: 22.8334\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 32.7181 - val_loss: 13.6941\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 26.6726 - val_loss: 17.3692\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 25.8285 - val_loss: 11.6235\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 21.3067 - val_loss: 11.4333\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 9us/step - loss: 20.0279 - val_loss: 12.7064\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 0us/step - loss: 21.2050 - val_loss: 19.6840\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 0us/step - loss: 20.6107 - val_loss: 13.1313\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 17.0029 - val_loss: 16.0783\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 0us/step - loss: 17.8225 - val_loss: 14.8043\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 17.8277 - val_loss: 11.9743\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 0us/step - loss: 14.9700 - val_loss: 10.5568\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 15.4635 - val_loss: 10.3904\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 14.8105 - val_loss: 11.4444\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 0us/step - loss: 15.7603 - val_loss: 12.4018\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 14.2578 - val_loss: 21.7290\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 0us/step - loss: 16.1147 - val_loss: 14.2986\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 14.0550 - val_loss: 25.1057\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 16.8881 - val_loss: 23.1802\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 0us/step - loss: 14.2806 - val_loss: 12.4319\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 69us/step - loss: 13.2090 - val_loss: 13.8710\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 81us/step - loss: 12.8069 - val_loss: 27.6029\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 13.9839 - val_loss: 17.3530\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 332us/step - loss: 606.2301 - val_loss: 488.0791\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 554.9836 - val_loss: 400.3211\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 335.3454 - val_loss: 57.6012\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 56.4186 - val_loss: 32.4457\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 36.2487 - val_loss: 31.9430\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 32.4402 - val_loss: 20.5391\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 26.5210 - val_loss: 19.7685\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 24.5598 - val_loss: 16.9711\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 22.1370 - val_loss: 14.8458\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 21.6147 - val_loss: 14.4329\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 20.3054 - val_loss: 16.1489\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 18.7737 - val_loss: 13.8100\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 17.4235 - val_loss: 22.7995\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 18.9160 - val_loss: 12.1940\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 16.0267 - val_loss: 11.6841\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.8123 - val_loss: 13.3449\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 15.2271 - val_loss: 18.2393\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.3981 - val_loss: 14.0566\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 14.3367 - val_loss: 11.3610\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.6461 - val_loss: 12.7042\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 14.3962 - val_loss: 10.9973\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 14.3571 - val_loss: 12.7762\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 13.1776 - val_loss: 16.1603\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.6519 - val_loss: 34.7718\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 52us/step - loss: 17.7782 - val_loss: 11.6051\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 12.0872 - val_loss: 10.9550\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.6445 - val_loss: 11.9223\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 12.0102 - val_loss: 11.0267\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 11.3048 - val_loss: 12.0366\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.4064 - val_loss: 10.6872\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.7970 - val_loss: 11.6783\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 10.5333 - val_loss: 13.7927\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 11.0209 - val_loss: 14.6560\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 12.2125 - val_loss: 16.8161\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.7480 - val_loss: 20.1005\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.9761 - val_loss: 10.8238\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 9.9797 - val_loss: 13.4246\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 9.9137 - val_loss: 11.7688\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 9.8482 - val_loss: 12.9233\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 10.4789 - val_loss: 11.3891\n",
      "56/56 [==============================] - 0s 18us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 266us/step - loss: 537.1896 - val_loss: 365.6217\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 284.2496 - val_loss: 74.2662\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 64.0202 - val_loss: 33.6615\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 33.7074 - val_loss: 33.7277\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 28.5445 - val_loss: 18.3928\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 19.9667 - val_loss: 15.7692\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 17.6500 - val_loss: 15.7982\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.5072 - val_loss: 14.5012\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.7400 - val_loss: 22.4677\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.1301 - val_loss: 15.6231\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 49us/step - loss: 14.4809 - val_loss: 11.7406\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 12.7146 - val_loss: 11.3150\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.1289 - val_loss: 13.3552\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.4579 - val_loss: 13.2863\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.8238 - val_loss: 12.1010\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.2551 - val_loss: 11.3959\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 10.8819 - val_loss: 11.2060\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.3435 - val_loss: 11.3122\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.1911 - val_loss: 11.3851\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 9.8239 - val_loss: 11.7372\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 9.7027 - val_loss: 13.4728\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 9.8934 - val_loss: 10.7573\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 9.1849 - val_loss: 11.9079\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 9.3083 - val_loss: 11.2017\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 8.8274 - val_loss: 10.9752\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 8.6230 - val_loss: 12.7459\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 8.8998 - val_loss: 11.3978\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.1695 - val_loss: 10.9453\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.2982 - val_loss: 11.3558\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.0627 - val_loss: 11.0167\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.8902 - val_loss: 11.0590\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.0599 - val_loss: 11.1913\n",
      "57/57 [==============================] - 0s 18us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 249us/step - loss: 590.6923 - val_loss: 381.2799\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 341.0788 - val_loss: 86.3528\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 77.1760 - val_loss: 40.1318\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 42.2745 - val_loss: 27.6653\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 32.9766 - val_loss: 22.3052\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 28.1378 - val_loss: 19.4515\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 25.6626 - val_loss: 24.0705\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.9925 - val_loss: 15.5136\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 21.7203 - val_loss: 16.9200\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 22.1651 - val_loss: 13.8720\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 20.2343 - val_loss: 14.8321\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 18.7555 - val_loss: 15.9999\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 18.8257 - val_loss: 15.2547\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.9469 - val_loss: 14.1376\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.9483 - val_loss: 13.2831\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.2783 - val_loss: 12.5514\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.7933 - val_loss: 19.7063\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 18.6803 - val_loss: 12.5515\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.4442 - val_loss: 13.1794\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.1598 - val_loss: 14.5239\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.2471 - val_loss: 12.3396\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.5568 - val_loss: 11.9652\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.6334 - val_loss: 11.8860\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.0787 - val_loss: 12.0257\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.1522 - val_loss: 11.6913\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.0201 - val_loss: 11.9804\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.5510 - val_loss: 12.2649\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 13.1905 - val_loss: 12.3792\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 40us/step - loss: 13.0526 - val_loss: 12.0392\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.5255 - val_loss: 12.8438\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.8458 - val_loss: 11.9631\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.2063 - val_loss: 13.5273\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.5724 - val_loss: 11.9399\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.3304 - val_loss: 11.5138\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.3178 - val_loss: 14.6620\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.9034 - val_loss: 11.4731\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.4932 - val_loss: 11.3149\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.4033 - val_loss: 13.5253\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.7649 - val_loss: 11.6123\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.4876 - val_loss: 13.8543\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.8512 - val_loss: 12.6006\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.0070 - val_loss: 11.6361\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.7699 - val_loss: 12.8946\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.3496 - val_loss: 11.7783\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.6938 - val_loss: 58.1626\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.4758 - val_loss: 15.2860\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.0095 - val_loss: 11.9286\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 320us/step - loss: 568.5307 - val_loss: 381.2846\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 297.8149 - val_loss: 80.3005\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 64.3457 - val_loss: 29.6452\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 36.2013 - val_loss: 53.6810\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 34.4544 - val_loss: 21.3750\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 25.7060 - val_loss: 21.2450\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.5582 - val_loss: 16.2479\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 22.0867 - val_loss: 15.1347\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 20.4458 - val_loss: 14.2128\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.0960 - val_loss: 13.7854\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 18.0830 - val_loss: 15.2143\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.6943 - val_loss: 13.5142\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.7892 - val_loss: 14.3552\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 15.8800 - val_loss: 15.5689\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.8522 - val_loss: 12.9877\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.0512 - val_loss: 13.8175\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.6961 - val_loss: 18.6393\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.2718 - val_loss: 13.3999\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.5226 - val_loss: 13.2995\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.4863 - val_loss: 15.7265\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.8518 - val_loss: 12.2967\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.8304 - val_loss: 13.2803\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.9724 - val_loss: 16.3058\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.3557 - val_loss: 11.9696\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.9722 - val_loss: 12.8623\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.7654 - val_loss: 13.1972\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.0384 - val_loss: 16.8014\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.5767 - val_loss: 12.1455\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.3620 - val_loss: 12.5972\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.2245 - val_loss: 13.0858\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.4684 - val_loss: 12.1977\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.7977 - val_loss: 11.9799\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.1932 - val_loss: 12.0355\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 10.8527 - val_loss: 12.9331\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 265us/step - loss: 588.9200 - val_loss: 349.5043\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 268.8251 - val_loss: 73.6391\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 71.1820 - val_loss: 33.4349\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 40.3494 - val_loss: 33.0319\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 34.0599 - val_loss: 20.0173\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 27.5739 - val_loss: 19.5758\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 25.5391 - val_loss: 17.1466\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 23.7345 - val_loss: 15.2793\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 21.9353 - val_loss: 15.4890\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 20.2855 - val_loss: 19.7434\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 22.4345 - val_loss: 13.7656\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 18.1980 - val_loss: 13.4679\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.7461 - val_loss: 13.2706\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 16.8816 - val_loss: 13.3971\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.8500 - val_loss: 14.1500\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.9197 - val_loss: 13.8529\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.5668 - val_loss: 17.8635\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.3453 - val_loss: 13.0710\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.9465 - val_loss: 12.3500\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.8795 - val_loss: 13.6471\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.0344 - val_loss: 16.0085\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.7172 - val_loss: 30.8035\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.2890 - val_loss: 14.5199\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 48us/step - loss: 13.8350 - val_loss: 14.8336\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.5515 - val_loss: 92.6175\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 25.7272 - val_loss: 15.6748\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.1925 - val_loss: 13.2621\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.6584 - val_loss: 13.4227\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.1935 - val_loss: 13.2570\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 256us/step - loss: 563.9389 - val_loss: 370.5491\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 292.5888 - val_loss: 72.6995\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 65.3804 - val_loss: 33.7966\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 33.4099 - val_loss: 22.4433\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 26.0640 - val_loss: 20.0216\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 22.5314 - val_loss: 15.7648\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 21.6083 - val_loss: 18.3925\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 20.6233 - val_loss: 14.7995\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 19.3937 - val_loss: 14.1799\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 18.1693 - val_loss: 13.2564\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 18.4525 - val_loss: 18.3939\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 18.2801 - val_loss: 12.6593\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 16.7826 - val_loss: 12.2042\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 16.2240 - val_loss: 13.0627\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 16.1992 - val_loss: 12.0960\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.8081 - val_loss: 11.8294\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 15.2556 - val_loss: 11.2926\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 14.4263 - val_loss: 13.8899\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 15.2463 - val_loss: 12.2856\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 14.5598 - val_loss: 30.9290\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 16.0966 - val_loss: 11.1773\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.2957 - val_loss: 11.5125\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.9866 - val_loss: 10.6664\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 13.1726 - val_loss: 11.4692\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.8842 - val_loss: 14.1772\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.4947 - val_loss: 10.6756\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.5920 - val_loss: 11.2703\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.9823 - val_loss: 11.0847\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.9872 - val_loss: 10.9683\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.8943 - val_loss: 12.0081\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.1470 - val_loss: 11.6778\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.2085 - val_loss: 17.9433\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 13.1958 - val_loss: 10.8749\n",
      "56/56 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 359us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 321us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "57/57 [==============================] - 0s 53us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 357us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 417us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 62us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: nan - val_loss: nan\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 363us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: nan - val_loss: nan\n",
      "56/56 [==============================] - 0s 53us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 312us/step - loss: 581.6566 - val_loss: 478.6476\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 519.5718 - val_loss: 375.8899\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 336.7358 - val_loss: 119.0866\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 86.4541 - val_loss: 46.6915\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 47.7509 - val_loss: 43.8632\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 52us/step - loss: 35.6592 - val_loss: 24.5638\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 25.9295 - val_loss: 20.9895\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 22.9526 - val_loss: 17.6009\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.5816 - val_loss: 16.3008\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 18.8539 - val_loss: 14.8119\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.7517 - val_loss: 13.8521\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 16.4597 - val_loss: 13.0079\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 15.6104 - val_loss: 26.2933\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.8822 - val_loss: 12.6339\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.7291 - val_loss: 16.6087\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.6579 - val_loss: 15.3343\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 13.4189 - val_loss: 11.6243\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.2538 - val_loss: 11.1900\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.8662 - val_loss: 11.0892\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.6960 - val_loss: 11.0861\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 11.4862 - val_loss: 10.6874\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 11.0216 - val_loss: 11.0233\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 10.9630 - val_loss: 10.6808\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.6854 - val_loss: 10.2479\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.4715 - val_loss: 10.2120\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.2805 - val_loss: 13.8511\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 10.7912 - val_loss: 10.4523\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.9603 - val_loss: 11.9789\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.2215 - val_loss: 10.1214\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.4715 - val_loss: 10.0024\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 9.2095 - val_loss: 10.1215\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.1443 - val_loss: 9.9729\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.9007 - val_loss: 9.9760\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.8254 - val_loss: 9.7525\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.6493 - val_loss: 9.6451\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.6242 - val_loss: 9.8393\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.4981 - val_loss: 9.8110\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 49us/step - loss: 8.4691 - val_loss: 9.5662\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.4743 - val_loss: 9.7569\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 8.2590 - val_loss: 9.5538\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.2450 - val_loss: 9.6615\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.9567 - val_loss: 10.9243\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.1700 - val_loss: 10.0364\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 7.8073 - val_loss: 9.7832\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 7.7309 - val_loss: 10.7146\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.8344 - val_loss: 11.5370\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 7.8182 - val_loss: 9.8028\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 7.4544 - val_loss: 10.1458\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 7.3494 - val_loss: 10.7212\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 7.7221 - val_loss: 11.3606\n",
      "57/57 [==============================] - 0s 17us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 307us/step - loss: 622.6344 - val_loss: 485.1393\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 578.0219 - val_loss: 426.9387\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 476.4840 - val_loss: 256.1033\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 202.7682 - val_loss: 51.2054\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 58.2300 - val_loss: 33.2478\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 40.9733 - val_loss: 26.0853\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 34.6200 - val_loss: 23.2901\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 30.4374 - val_loss: 27.7968\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 29.2041 - val_loss: 20.7706\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 25.6606 - val_loss: 15.8146\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 23.8148 - val_loss: 15.2759\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 22.2605 - val_loss: 14.5515\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 21.4775 - val_loss: 14.6114\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 62us/step - loss: 20.7928 - val_loss: 14.0926\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.6959 - val_loss: 14.3901\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 19.2750 - val_loss: 32.9877\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 22.7896 - val_loss: 14.4060\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.5981 - val_loss: 14.0810\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.7530 - val_loss: 14.4118\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.5303 - val_loss: 14.6654\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 16.7465 - val_loss: 17.4177\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.8483 - val_loss: 12.9904\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.6745 - val_loss: 12.9718\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.0333 - val_loss: 13.1535\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 15.1432 - val_loss: 14.1597\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.4125 - val_loss: 12.5487\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.4242 - val_loss: 13.0303\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.2881 - val_loss: 13.4136\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.3279 - val_loss: 12.3276\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.0035 - val_loss: 13.4690\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.1085 - val_loss: 12.4988\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 13.3390 - val_loss: 12.1189\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.0875 - val_loss: 16.7603\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 14.0778 - val_loss: 12.0870\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.9349 - val_loss: 11.8215\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 12.7879 - val_loss: 12.8314\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.7890 - val_loss: 11.9801\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.7958 - val_loss: 11.8109\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.2389 - val_loss: 12.0817\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.5391 - val_loss: 12.1031\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.8886 - val_loss: 11.6401\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.0865 - val_loss: 11.5395\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.7459 - val_loss: 11.9586\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.7244 - val_loss: 13.0805\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.2796 - val_loss: 14.6986\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.5575 - val_loss: 11.5453\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.6494 - val_loss: 11.4659\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.6005 - val_loss: 11.2012\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 84us/step - loss: 11.1001 - val_loss: 11.1232\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 11.3855 - val_loss: 11.0822\n",
      "Epoch 51/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 10.7340 - val_loss: 14.7321\n",
      "Epoch 52/100\n",
      "227/227 [==============================] - 0s 70us/step - loss: 12.0513 - val_loss: 11.6838\n",
      "Epoch 53/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.6371 - val_loss: 11.1761\n",
      "Epoch 54/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 10.5766 - val_loss: 11.1751\n",
      "Epoch 55/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.2853 - val_loss: 20.3142\n",
      "Epoch 56/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 11.7405 - val_loss: 11.8023\n",
      "Epoch 57/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.3990 - val_loss: 11.7768\n",
      "Epoch 58/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.1894 - val_loss: 13.0184\n",
      "Epoch 59/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.5904 - val_loss: 11.5192\n",
      "Epoch 60/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.0041 - val_loss: 11.4824\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 299us/step - loss: 606.4288 - val_loss: 483.7486\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 552.5116 - val_loss: 415.5574\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 432.5364 - val_loss: 232.2964\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 47us/step - loss: 170.9296 - val_loss: 61.8083\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 73.2540 - val_loss: 41.6328\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 52.7977 - val_loss: 29.0686\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 40.1161 - val_loss: 24.3074\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 34.2099 - val_loss: 19.1565\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 29.3441 - val_loss: 17.2424\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 27.5919 - val_loss: 19.5743\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 25.9868 - val_loss: 15.2882\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 24.2023 - val_loss: 14.4091\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 23.3661 - val_loss: 13.8112\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 21.4969 - val_loss: 15.8489\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 22.2949 - val_loss: 12.5806\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.3330 - val_loss: 12.8913\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.1873 - val_loss: 13.0111\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 18.6270 - val_loss: 12.4601\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.8986 - val_loss: 11.8358\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.3393 - val_loss: 11.7875\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.9571 - val_loss: 11.5799\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.4421 - val_loss: 11.6106\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.1937 - val_loss: 14.0374\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.2464 - val_loss: 11.6074\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.3414 - val_loss: 17.9239\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.2104 - val_loss: 12.1110\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.0246 - val_loss: 11.4386\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.6392 - val_loss: 11.4537\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.3074 - val_loss: 11.7312\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.9869 - val_loss: 11.4265\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 44us/step - loss: 13.6737 - val_loss: 11.6908\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.7006 - val_loss: 11.4814\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.6109 - val_loss: 13.1122\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 13.6301 - val_loss: 13.0413\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.7179 - val_loss: 11.5008\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.9427 - val_loss: 12.0217\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.7177 - val_loss: 13.1869\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.0773 - val_loss: 11.5142\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.6860 - val_loss: 26.2710\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.4648 - val_loss: 12.0824\n",
      "57/57 [==============================] - 0s 34us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 294us/step - loss: 640.0879 - val_loss: 473.0605\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 567.7538 - val_loss: 370.8584\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 374.3881 - val_loss: 128.6579\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 97.3481 - val_loss: 39.6656\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 46.0079 - val_loss: 28.5796\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 37.3262 - val_loss: 22.6920\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 31.5375 - val_loss: 21.3919\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 29.0520 - val_loss: 17.1154\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 26.4089 - val_loss: 19.1545\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 24.8328 - val_loss: 15.0977\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.8699 - val_loss: 19.9813\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 24.2437 - val_loss: 14.4630\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 21.8030 - val_loss: 14.2365\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.7668 - val_loss: 13.6783\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.7543 - val_loss: 12.9901\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.0258 - val_loss: 13.8057\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 19.1404 - val_loss: 13.1921\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.8742 - val_loss: 13.1335\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.7434 - val_loss: 12.9300\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.3268 - val_loss: 12.2685\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.2178 - val_loss: 15.9865\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.6164 - val_loss: 12.2250\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.8721 - val_loss: 12.3394\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.4767 - val_loss: 12.1203\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.0763 - val_loss: 12.0078\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.9133 - val_loss: 12.1009\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.4117 - val_loss: 12.3863\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.9666 - val_loss: 13.5512\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.8502 - val_loss: 11.7083\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.0929 - val_loss: 18.2709\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.2757 - val_loss: 12.0551\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.4954 - val_loss: 12.6700\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.3176 - val_loss: 18.3084\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.2976 - val_loss: 13.1272\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.8136 - val_loss: 15.6341\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.1979 - val_loss: 12.8071\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.9592 - val_loss: 12.0034\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.3533 - val_loss: 11.5319\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.1661 - val_loss: 13.7651\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.2207 - val_loss: 13.1009\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.7270 - val_loss: 12.0882\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.7395 - val_loss: 12.2963\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.3199 - val_loss: 11.7913\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 11.6529 - val_loss: 15.1136\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.6766 - val_loss: 11.0407\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.5715 - val_loss: 11.2633\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.4602 - val_loss: 11.5928\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.2424 - val_loss: 12.6986\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.3178 - val_loss: 18.8213\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.6434 - val_loss: 12.8305\n",
      "Epoch 51/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.9809 - val_loss: 11.9656\n",
      "Epoch 52/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.4119 - val_loss: 13.0884\n",
      "Epoch 53/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.6356 - val_loss: 46.2262\n",
      "Epoch 54/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.5140 - val_loss: 13.1349\n",
      "Epoch 55/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.5146 - val_loss: 15.2993\n",
      "57/57 [==============================] - 0s 34us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 326us/step - loss: 600.9680 - val_loss: 482.8467\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 550.2840 - val_loss: 417.1464\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 435.1961 - val_loss: 225.2829\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 164.7142 - val_loss: 64.0036\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 65.6066 - val_loss: 44.1434\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 45.5508 - val_loss: 30.6944\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 32.1420 - val_loss: 32.1041\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 66us/step - loss: 29.1794 - val_loss: 18.9921\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 23.2766 - val_loss: 17.3349\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 21.7293 - val_loss: 17.9572\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 21.0344 - val_loss: 16.2427\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 57us/step - loss: 19.7320 - val_loss: 15.3953\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 19.0748 - val_loss: 15.1612\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 18.8079 - val_loss: 19.0733\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 19.6910 - val_loss: 12.8564\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 17.5905 - val_loss: 12.7610\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 16.8500 - val_loss: 12.4906\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 16.5102 - val_loss: 12.6697\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 16.1030 - val_loss: 12.6707\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 15.7970 - val_loss: 14.5257\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 16.0389 - val_loss: 11.8923\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.0998 - val_loss: 12.2613\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 15.3405 - val_loss: 11.7401\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 14.8161 - val_loss: 11.5901\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 14.4244 - val_loss: 12.3183\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 14.4387 - val_loss: 19.3480\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 16.3070 - val_loss: 11.9203\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 13.8633 - val_loss: 17.2634\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 15.8829 - val_loss: 11.9031\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.9671 - val_loss: 11.6711\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.4541 - val_loss: 11.5073\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.2265 - val_loss: 11.4874\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 12.9588 - val_loss: 11.4041\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 13.2571 - val_loss: 12.0433\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.7426 - val_loss: 12.2401\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.7464 - val_loss: 11.2761\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 12.2815 - val_loss: 11.2280\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 12.1631 - val_loss: 11.7730\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 12.2615 - val_loss: 11.8398\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 12.0712 - val_loss: 11.7293\n",
      "Epoch 41/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.8770 - val_loss: 12.9861\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 12.6571 - val_loss: 11.4029\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 11.9885 - val_loss: 14.2474\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 74us/step - loss: 13.3978 - val_loss: 12.4989\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 12.2718 - val_loss: 12.3949\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 74us/step - loss: 11.9121 - val_loss: 12.7118\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 70us/step - loss: 11.8083 - val_loss: 11.7237\n",
      "56/56 [==============================] - 0s 160us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 259us/step - loss: 520.5671 - val_loss: 271.8500\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 128.2382 - val_loss: 50.2014\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 36.8998 - val_loss: 27.6773\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 28.2010 - val_loss: 19.3876\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 22.8156 - val_loss: 20.9878\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 21.6241 - val_loss: 21.9154\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 18.4525 - val_loss: 14.5310\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.7128 - val_loss: 25.4130\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 18.4717 - val_loss: 18.7118\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.4504 - val_loss: 12.6401\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.3186 - val_loss: 13.7097\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.7638 - val_loss: 13.6784\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.0589 - val_loss: 31.2688\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.2921 - val_loss: 11.9926\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.7744 - val_loss: 11.9443\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.2596 - val_loss: 11.0980\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.5200 - val_loss: 10.7752\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.1095 - val_loss: 14.7283\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.2455 - val_loss: 19.9744\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.6418 - val_loss: 11.0852\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 9.1326 - val_loss: 11.3127\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 9.2545 - val_loss: 12.4249\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.8184 - val_loss: 16.4006\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 9.7095 - val_loss: 12.5937\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 8.8714 - val_loss: 11.1633\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 7.9578 - val_loss: 9.9074\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.9783 - val_loss: 10.1714\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 7.8002 - val_loss: 26.2672\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.6105 - val_loss: 10.8649\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 7.2723 - val_loss: 23.5189\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.9875 - val_loss: 11.1833\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.1692 - val_loss: 32.7935\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.9801 - val_loss: 12.2936\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 7.4590 - val_loss: 10.0965\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 6.8115 - val_loss: 10.6090\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.7096 - val_loss: 13.1733\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 289us/step - loss: 492.7347 - val_loss: 145.3591\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 107.8194 - val_loss: 29.5758\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 31.5212 - val_loss: 41.2410\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 29.4532 - val_loss: 22.1072\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 44us/step - loss: 23.4363 - val_loss: 15.7043\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.8307 - val_loss: 12.3443\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 18.7817 - val_loss: 12.0147\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.7174 - val_loss: 11.9696\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.1190 - val_loss: 11.8238\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.4328 - val_loss: 15.8837\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.2055 - val_loss: 16.6729\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.7148 - val_loss: 12.4965\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.3717 - val_loss: 12.4428\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.9627 - val_loss: 13.0228\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.4057 - val_loss: 14.8392\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.2033 - val_loss: 12.0180\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.0424 - val_loss: 12.4705\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.7293 - val_loss: 11.6424\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.9056 - val_loss: 13.3825\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.1832 - val_loss: 12.3149\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.2553 - val_loss: 13.4721\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.0985 - val_loss: 42.6288\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 33.0243 - val_loss: 15.0451\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 15.8422 - val_loss: 13.4464\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 62us/step - loss: 14.6486 - val_loss: 12.5980\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 75us/step - loss: 13.4875 - val_loss: 25.6467\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 22.9363 - val_loss: 12.9789\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.0627 - val_loss: 11.9106\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 271us/step - loss: 493.6808 - val_loss: 113.7951\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 84.9274 - val_loss: 30.7124\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 36.9826 - val_loss: 46.5485\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 33.7824 - val_loss: 21.3679\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.1500 - val_loss: 16.2352\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.0701 - val_loss: 14.6053\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.2500 - val_loss: 13.8833\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.4167 - val_loss: 20.5655\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.5619 - val_loss: 15.2032\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.9439 - val_loss: 15.5257\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.0406 - val_loss: 16.0724\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.1096 - val_loss: 16.6525\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.4740 - val_loss: 14.9634\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.4468 - val_loss: 13.3005\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.3625 - val_loss: 41.8868\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.7510 - val_loss: 12.7704\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.6014 - val_loss: 23.0427\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.0401 - val_loss: 12.3152\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.6892 - val_loss: 18.7637\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.9120 - val_loss: 12.8033\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.1862 - val_loss: 12.4987\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.7051 - val_loss: 13.8754\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.7044 - val_loss: 12.6626\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 9.9977 - val_loss: 18.2643\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.7664 - val_loss: 13.8022\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.4440 - val_loss: 14.7584\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 10.2984 - val_loss: 16.3545\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.2231 - val_loss: 66.7301\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 260us/step - loss: 456.3414 - val_loss: 88.1956\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 70.2195 - val_loss: 32.4782\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 37.5403 - val_loss: 16.6139\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 28.2343 - val_loss: 13.7539\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.5126 - val_loss: 12.6545\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 22.1303 - val_loss: 17.1458\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 21.6659 - val_loss: 13.1609\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.4620 - val_loss: 12.2600\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 18.5536 - val_loss: 12.4939\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.4972 - val_loss: 102.4934\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 26.4759 - val_loss: 12.3719\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.1386 - val_loss: 12.8433\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 15.4181 - val_loss: 11.9984\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.8577 - val_loss: 23.7939\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.5329 - val_loss: 11.6661\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.8681 - val_loss: 11.0951\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 13.8897 - val_loss: 14.6324\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.2229 - val_loss: 11.4908\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.0161 - val_loss: 51.5080\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.1092 - val_loss: 15.3821\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 13.2822 - val_loss: 17.9226\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.9559 - val_loss: 12.6922\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 66us/step - loss: 13.2171 - val_loss: 166.3348\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 30.3479 - val_loss: 16.7076\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 48us/step - loss: 12.0879 - val_loss: 13.1414\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.3440 - val_loss: 11.3841\n",
      "57/57 [==============================] - 0s 53us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 251us/step - loss: 485.5460 - val_loss: 177.8311\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 107.2258 - val_loss: 37.9112\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 40us/step - loss: 31.8606 - val_loss: 19.9464\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 25.2943 - val_loss: 19.6095\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 22.6659 - val_loss: 20.7636\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 22.5273 - val_loss: 23.4827\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 20.4900 - val_loss: 17.2901\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 18.9479 - val_loss: 17.5731\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 17.6956 - val_loss: 14.2872\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 16.7427 - val_loss: 28.0321\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 23.1540 - val_loss: 13.4832\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 17.0780 - val_loss: 13.2077\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 16.1276 - val_loss: 15.6441\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 16.8645 - val_loss: 14.0242\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 15.2839 - val_loss: 14.3552\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 16.4715 - val_loss: 11.4573\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 13.9303 - val_loss: 11.9840\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 40us/step - loss: 13.4131 - val_loss: 14.4964\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 13.9815 - val_loss: 14.3012\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 13.1619 - val_loss: 13.4322\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.6048 - val_loss: 11.6390\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.9819 - val_loss: 11.1325\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.5748 - val_loss: 16.8170\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.3385 - val_loss: 14.7498\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.8977 - val_loss: 20.8257\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 13.4486 - val_loss: 20.3538\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 13.4959 - val_loss: 10.4373\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 11.4850 - val_loss: 10.6886\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 10.8606 - val_loss: 12.7585\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 11.8434 - val_loss: 10.7404\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 10.8110 - val_loss: 10.7864\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 10.8934 - val_loss: 10.8607\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 10.7973 - val_loss: 13.2409\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 10.7090 - val_loss: 12.7065\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 10.9086 - val_loss: 15.0597\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 10.6840 - val_loss: 11.5564\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 10.3123 - val_loss: 19.2093\n",
      "56/56 [==============================] - 0s 36us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 242us/step - loss: 508.6853 - val_loss: 162.1658\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12702.1376 - val_loss: 129.7584\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 154.0861 - val_loss: 95.0360\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 121.4395 - val_loss: 77.8488\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 104.0178 - val_loss: 68.3655\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 93.7925 - val_loss: 64.9268\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 89.6396 - val_loss: 63.0378\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 86.8860 - val_loss: 61.1976\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 83.5296 - val_loss: 61.0539\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 82.8418 - val_loss: 61.1517\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 81.9963 - val_loss: 61.1977\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 81.8675 - val_loss: 61.6030\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 81.4952 - val_loss: 61.9493\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 81.3526 - val_loss: 61.7228\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 81.3956 - val_loss: 61.7109\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 81.3799 - val_loss: 61.6113\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 2748.0362 - val_loss: 64.4839\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 89.2323 - val_loss: 61.8248\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 85.0052 - val_loss: 61.3598\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 263us/step - loss: 604.6247 - val_loss: 245.0800\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 566.0453 - val_loss: 29565.3937\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 85026.8196 - val_loss: 1035.3649\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: inf - val_loss: nan\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 272us/step - loss: 1316.7319 - val_loss: 405.6219\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 415.4146 - val_loss: 178.2712\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 310.2620 - val_loss: 136.0240\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 95430.6486 - val_loss: 781.3474\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 9735.6240 - val_loss: 976.9207\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 264us/step - loss: 758.2997 - val_loss: 403.1421\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 28266.8849 - val_loss: 3667.5784\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "57/57 [==============================] - 0s 34us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 261us/step - loss: 1531.2851 - val_loss: 216.2259\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 697.7612 - val_loss: 367397346.0211\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 74us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 66us/step - loss: nan - val_loss: nan\n",
      "56/56 [==============================] - 0s 53us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 316us/step - loss: 464.4415 - val_loss: 94.6897\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 251.2738 - val_loss: 129.1877\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 143.0456 - val_loss: 284.2814\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 424.5907 - val_loss: 134.7881\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 73.7385 - val_loss: 202.1960\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 153.0741 - val_loss: 392.8435\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 114.3963 - val_loss: 28.5276\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 27.0013 - val_loss: 15.2614\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.9185 - val_loss: 13.7016\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.4256 - val_loss: 10.9930\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.3546 - val_loss: 12.2327\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.3586 - val_loss: 40.7240\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 37.4539 - val_loss: 12.9793\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 11.3399 - val_loss: 10.3434\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.5425 - val_loss: 10.9367\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.2748 - val_loss: 13.2867\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.1429 - val_loss: 10.8828\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 8.3092 - val_loss: 55.8767\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 19.0887 - val_loss: 11.6460\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.2625 - val_loss: 10.7839\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 9.1876 - val_loss: 11.3143\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 7.2327 - val_loss: 10.9348\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.1142 - val_loss: 24.1410\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.5739 - val_loss: 17.8626\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 362us/step - loss: 450.9084 - val_loss: 324.4053\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 231.3031 - val_loss: 127.9940\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 102.7896 - val_loss: 2680.7605\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 964.0490 - val_loss: 372.1413\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 445.4855 - val_loss: 554.1680\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 365.0765 - val_loss: 6143.8522\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 1232.9670 - val_loss: 398.9336\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 490.9140 - val_loss: 368.7295\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 454.8413 - val_loss: 332.2985\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 395.6142 - val_loss: 201.1039\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 135.6347 - val_loss: 51.0176\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 93.6105 - val_loss: 30.6335\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 49.4337 - val_loss: 42.9408\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 74.9764 - val_loss: 19.3123\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 33.2239 - val_loss: 15.0806\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 30.5730 - val_loss: 30.6604\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 37.6287 - val_loss: 13.5835\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 27.2087 - val_loss: 27.4149\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 33.5433 - val_loss: 67.2290\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 60.0353 - val_loss: 54.9916\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 39.2458 - val_loss: 13.6687\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 29.1447 - val_loss: 17.0024\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 25.9501 - val_loss: 16.0999\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 48us/step - loss: 25.4220 - val_loss: 12.0524\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.5540 - val_loss: 22.8616\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 23.9867 - val_loss: 11.9510\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 19.6040 - val_loss: 11.3176\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 18.3686 - val_loss: 75.1304\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 38.3400 - val_loss: 18.3840\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 24.2216 - val_loss: 12.2533\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 19.5161 - val_loss: 11.6523\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.8556 - val_loss: 31.9110\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 24.9675 - val_loss: 11.2442\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.9249 - val_loss: 12.7942\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.9243 - val_loss: 13.0835\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.5644 - val_loss: 10.3460\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 18.0729 - val_loss: 24.5503\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 19.5368 - val_loss: 29.0685\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.2021 - val_loss: 11.1206\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.8369 - val_loss: 19.4226\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 18.7742 - val_loss: 11.0147\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 18.6194 - val_loss: 12.9365\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.5929 - val_loss: 21.4865\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.6924 - val_loss: 18.3713\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.4719 - val_loss: 11.2844\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.7434 - val_loss: 10.7981\n",
      "57/57 [==============================] - 0s 18us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 314us/step - loss: 466.4435 - val_loss: 388.7623\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 177.8604 - val_loss: 29.9637\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 84.9311 - val_loss: 44.2312\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 98.7100 - val_loss: 159.3255\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 94.5252 - val_loss: 21.6887\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 29.3202 - val_loss: 94.4967\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 132.1040 - val_loss: 30.0435\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 217.7895 - val_loss: 73.9260\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 38.0568 - val_loss: 23.6886\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 41.3484 - val_loss: 16.0729\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.1475 - val_loss: 21.4071\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 23.4813 - val_loss: 13.1349\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.8633 - val_loss: 33.8488\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 27.1701 - val_loss: 217.6695\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 221.6409 - val_loss: 43.5475\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 45.2942 - val_loss: 71.3659\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 42.0055 - val_loss: 136.6822\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 75.7614 - val_loss: 24.5783\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 27.3975 - val_loss: 36.0848\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 26.1404 - val_loss: 131.6928\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 42.1832 - val_loss: 16.2175\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.8391 - val_loss: 13.5064\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 343us/step - loss: 411.6113 - val_loss: 500.2111\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 594.6425 - val_loss: 318.5793\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 222.9273 - val_loss: 341.1294\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 203.5042 - val_loss: 424.0325\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 484.7663 - val_loss: 179.6746\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 168.1326 - val_loss: 2909.7896\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 980.8361 - val_loss: 186.5132\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 249.0142 - val_loss: 349.7455\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 339.6700 - val_loss: 315.9563\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 265.1231 - val_loss: 57.3373\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 77.9706 - val_loss: 100.5483\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 120.4286 - val_loss: 28.0075\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 153.4689 - val_loss: 99.9272\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 72.3287 - val_loss: 79.2278\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 65.5545 - val_loss: 27.9838\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 27.8467 - val_loss: 15.8847\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 34.4878 - val_loss: 25.7945\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 20.1874 - val_loss: 16.3462\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 15.9342 - val_loss: 27.0065\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 16.3731 - val_loss: 12.0469\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.2650 - val_loss: 90.2817\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 45.4821 - val_loss: 76.3143\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 98.9160 - val_loss: 306.9438\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 94.5858 - val_loss: 33.2445\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.8264 - val_loss: 22.7417\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 19.6417 - val_loss: 169.2118\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 35.6414 - val_loss: 18.4358\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.5511 - val_loss: 13.0751\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.6868 - val_loss: 23.3659\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.5531 - val_loss: 11.3194\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.4798 - val_loss: 12.3617\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 53us/step - loss: 8.9300 - val_loss: 11.5352\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.1624 - val_loss: 18.1269\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 9.9013 - val_loss: 25.9778\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 10.3106 - val_loss: 14.3307\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.5741 - val_loss: 12.7144\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.5583 - val_loss: 247.5416\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 119.6665 - val_loss: 25.8268\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 32.4283 - val_loss: 52.0106\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 25.3809 - val_loss: 22.9239\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 351us/step - loss: 443.6024 - val_loss: 40.3748\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 235.0320 - val_loss: 190.3814\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 195.8135 - val_loss: 389.6149\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 271.0127 - val_loss: 27.1573\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 60.1921 - val_loss: 51.2778\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 97.5300 - val_loss: 87.5914\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 44.7361 - val_loss: 20.1245\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 36.3442 - val_loss: 17.8223\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 47.5350 - val_loss: 64.2975\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 41.9214 - val_loss: 10.3292\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 40us/step - loss: 28.0329 - val_loss: 11.9955\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 35us/step - loss: 15.8225 - val_loss: 12.6839\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 12.0742 - val_loss: 9.2736\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 24.0730 - val_loss: 11.8827\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.7834 - val_loss: 406.5059\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 172.7463 - val_loss: 164.8110\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 118.6155 - val_loss: 21.5710\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 28.7329 - val_loss: 13.6911\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 16.4724 - val_loss: 13.2205\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 16.3582 - val_loss: 20.3162\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 14.9666 - val_loss: 15.9165\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 14.5905 - val_loss: 19.3875\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 14.1396 - val_loss: 66.7425\n",
      "56/56 [==============================] - 0s 17us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 195us/step - loss: 512.6050 - val_loss: 329.6033\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 265.3575 - val_loss: 73.8099\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 59.0661 - val_loss: 38.7768\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 36.2459 - val_loss: 29.2132\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 29.8849 - val_loss: 23.9113\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 26.5848 - val_loss: 25.4683\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 25.2076 - val_loss: 21.6702\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 23.4956 - val_loss: 20.1511\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 22.9052 - val_loss: 19.9945\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 21.0859 - val_loss: 18.4971\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.0628 - val_loss: 18.2643\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.2695 - val_loss: 17.4050\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.0310 - val_loss: 16.8488\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 17.9857 - val_loss: 33.6461\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.2471 - val_loss: 17.8668\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 16.5406 - val_loss: 19.0560\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.5215 - val_loss: 16.2913\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.4271 - val_loss: 15.7202\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.9572 - val_loss: 15.0231\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 14.6428 - val_loss: 15.3224\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.4514 - val_loss: 14.5844\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.0862 - val_loss: 15.3024\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.2193 - val_loss: 13.6625\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 13.4124 - val_loss: 14.3173\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.5322 - val_loss: 13.7860\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.9043 - val_loss: 12.8693\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.8615 - val_loss: 12.8066\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.5646 - val_loss: 13.1818\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.4587 - val_loss: 12.5627\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.0005 - val_loss: 12.4546\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.8581 - val_loss: 11.7867\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.8185 - val_loss: 11.6482\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 11.5150 - val_loss: 14.4970\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.9411 - val_loss: 11.9412\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.1942 - val_loss: 11.7619\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.2412 - val_loss: 11.1799\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.8587 - val_loss: 11.3863\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 10.6181 - val_loss: 11.6478\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.4878 - val_loss: 11.4552\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 10.2628 - val_loss: 12.2434\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.0530 - val_loss: 12.8390\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 10.4403 - val_loss: 11.9531\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 10.0644 - val_loss: 11.0037\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 9.7936 - val_loss: 12.1715\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 39us/step - loss: 10.2593 - val_loss: 12.5213\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 9.9702 - val_loss: 10.6903\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 9.4363 - val_loss: 10.6824\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 9.2402 - val_loss: 10.4249\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 9.2896 - val_loss: 13.3158\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 9.5596 - val_loss: 10.5147\n",
      "Epoch 51/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 9.0210 - val_loss: 10.7365\n",
      "Epoch 52/100\n",
      "227/227 [==============================] - 0s 61us/step - loss: 9.0247 - val_loss: 10.2470\n",
      "Epoch 53/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.8099 - val_loss: 10.9325\n",
      "Epoch 54/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.7976 - val_loss: 10.9089\n",
      "Epoch 55/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.6124 - val_loss: 9.7611\n",
      "Epoch 56/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.6112 - val_loss: 9.9033\n",
      "Epoch 57/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 8.9573 - val_loss: 9.8517\n",
      "Epoch 58/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.6673 - val_loss: 9.6965\n",
      "Epoch 59/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 8.5357 - val_loss: 10.0996\n",
      "Epoch 60/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.2650 - val_loss: 9.6874\n",
      "Epoch 61/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.2812 - val_loss: 10.4336\n",
      "Epoch 62/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 8.1636 - val_loss: 11.2788\n",
      "Epoch 63/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.4541 - val_loss: 10.1989\n",
      "Epoch 64/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.9203 - val_loss: 9.7287\n",
      "Epoch 65/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 8.0840 - val_loss: 10.3400\n",
      "Epoch 66/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 7.8397 - val_loss: 11.7476\n",
      "Epoch 67/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 8.1824 - val_loss: 11.2808\n",
      "Epoch 68/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 7.9652 - val_loss: 10.8632\n",
      "Epoch 69/100\n",
      "227/227 [==============================] - 0s 79us/step - loss: 7.7455 - val_loss: 10.1156\n",
      "Epoch 70/100\n",
      "227/227 [==============================] - 0s 123us/step - loss: 7.5590 - val_loss: 10.5773\n",
      "57/57 [==============================] - 0s 52us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 215us/step - loss: 582.2727 - val_loss: 356.2410\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 331.6227 - val_loss: 119.2586\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 115.4415 - val_loss: 48.1522\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 56.5070 - val_loss: 29.5829\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 37.5881 - val_loss: 23.7597\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 31.9063 - val_loss: 23.4869\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 30.7844 - val_loss: 20.5217\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 27.9818 - val_loss: 20.5765\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 27.1079 - val_loss: 19.9463\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 25.9550 - val_loss: 18.2481\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.5031 - val_loss: 17.4793\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 23.5966 - val_loss: 16.9866\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 22.6711 - val_loss: 29.8815\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.1213 - val_loss: 18.1034\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.4768 - val_loss: 16.8774\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 19.8897 - val_loss: 16.3669\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 19.4326 - val_loss: 17.3767\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.7716 - val_loss: 15.1377\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 18.1884 - val_loss: 14.9608\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.9791 - val_loss: 15.7615\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 18.1035 - val_loss: 20.5228\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 20.1217 - val_loss: 15.1816\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 17.8068 - val_loss: 16.6041\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.3595 - val_loss: 14.1629\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.4397 - val_loss: 13.7911\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 16.3418 - val_loss: 13.4236\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.7022 - val_loss: 13.4657\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 15.5436 - val_loss: 13.1747\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.4609 - val_loss: 13.3447\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.1902 - val_loss: 13.1318\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 15.0802 - val_loss: 12.4883\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.7636 - val_loss: 12.2126\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.3538 - val_loss: 12.8074\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.4428 - val_loss: 11.9486\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.1446 - val_loss: 11.8800\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 14.0667 - val_loss: 12.0460\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.9421 - val_loss: 12.2495\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.8428 - val_loss: 12.0299\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 13.6467 - val_loss: 11.8936\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.4478 - val_loss: 11.9330\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 13.3905 - val_loss: 11.5241\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 13.0151 - val_loss: 11.5233\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.1632 - val_loss: 11.8628\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 13.0998 - val_loss: 11.7464\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.9839 - val_loss: 12.2004\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.4448 - val_loss: 11.2545\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.7054 - val_loss: 11.2870\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.8100 - val_loss: 11.0696\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.7652 - val_loss: 11.5696\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.9596 - val_loss: 11.2299\n",
      "Epoch 51/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.4366 - val_loss: 11.1830\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 35us/step - loss: 12.1278 - val_loss: 11.2736\n",
      "Epoch 53/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.0489 - val_loss: 11.5188\n",
      "Epoch 54/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 12.1250 - val_loss: 14.1302\n",
      "Epoch 55/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.7906 - val_loss: 11.8007\n",
      "Epoch 56/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.2976 - val_loss: 11.7456\n",
      "Epoch 57/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.8237 - val_loss: 19.2834\n",
      "Epoch 58/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 13.4703 - val_loss: 13.1963\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 228us/step - loss: 531.8994 - val_loss: 240.7020\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 183.7591 - val_loss: 75.3127\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 73.2955 - val_loss: 55.0571\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 49.9322 - val_loss: 27.7183\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 33.8466 - val_loss: 21.9858\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 28.8946 - val_loss: 21.0384\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 27.1864 - val_loss: 17.7491\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 24.2674 - val_loss: 17.8084\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 23.2576 - val_loss: 15.6852\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 21.4670 - val_loss: 15.9427\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 21.1774 - val_loss: 15.0488\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 20.1016 - val_loss: 13.8793\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 19.0595 - val_loss: 17.5184\n",
      "Epoch 14/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 19.4502 - val_loss: 13.7082\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.7554 - val_loss: 13.4147\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 17.5200 - val_loss: 13.3426\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.1250 - val_loss: 13.6485\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.7229 - val_loss: 12.8496\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 16.5417 - val_loss: 14.5612\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 16.4446 - val_loss: 12.6332\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.7656 - val_loss: 13.2369\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.7033 - val_loss: 12.5280\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.0039 - val_loss: 13.4950\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 15.0253 - val_loss: 12.2423\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 14.4207 - val_loss: 11.9292\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.1920 - val_loss: 12.0917\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.3347 - val_loss: 11.7792\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 14.1279 - val_loss: 11.5061\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.6702 - val_loss: 11.6059\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 13.4062 - val_loss: 11.3921\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.3770 - val_loss: 11.4519\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.1986 - val_loss: 11.3404\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.1155 - val_loss: 12.3417\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.0444 - val_loss: 11.1638\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.6070 - val_loss: 11.0126\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.5371 - val_loss: 11.0258\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 12.7892 - val_loss: 10.9233\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.3413 - val_loss: 11.6674\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.4416 - val_loss: 11.5796\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.1988 - val_loss: 11.8301\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.7615 - val_loss: 12.1228\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.1180 - val_loss: 11.9276\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 12.1501 - val_loss: 11.2222\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.0067 - val_loss: 11.0624\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 11.6980 - val_loss: 10.9322\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.4984 - val_loss: 10.7445\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.4584 - val_loss: 11.1670\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.4726 - val_loss: 17.3108\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.6965 - val_loss: 11.2566\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.3781 - val_loss: 12.5837\n",
      "Epoch 51/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.3511 - val_loss: 11.0332\n",
      "Epoch 52/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 11.2748 - val_loss: 11.0560\n",
      "Epoch 53/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 11.5730 - val_loss: 10.8973\n",
      "Epoch 54/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.0197 - val_loss: 10.9047\n",
      "Epoch 55/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 11.2592 - val_loss: 12.0771\n",
      "Epoch 56/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 11.1724 - val_loss: 11.0985\n",
      "57/57 [==============================] - 0s 53us/step\n",
      "Train on 227 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "227/227 [==============================] - 0s 215us/step - loss: 552.4512 - val_loss: 271.8724\n",
      "Epoch 2/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 239.0270 - val_loss: 95.2725\n",
      "Epoch 3/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 95.7499 - val_loss: 34.7353\n",
      "Epoch 4/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 43.9163 - val_loss: 23.5642\n",
      "Epoch 5/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 35.4734 - val_loss: 23.7121\n",
      "Epoch 6/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 33.0015 - val_loss: 20.0512\n",
      "Epoch 7/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 29.9992 - val_loss: 19.2801\n",
      "Epoch 8/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 28.6862 - val_loss: 18.1212\n",
      "Epoch 9/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 26.6504 - val_loss: 17.4357\n",
      "Epoch 10/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 25.5327 - val_loss: 16.1607\n",
      "Epoch 11/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 24.4037 - val_loss: 15.6992\n",
      "Epoch 12/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 23.5569 - val_loss: 15.8527\n",
      "Epoch 13/100\n",
      "227/227 [==============================] - 0s 57us/step - loss: 22.8116 - val_loss: 14.8853\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 40us/step - loss: 21.9401 - val_loss: 22.6430\n",
      "Epoch 15/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 23.6617 - val_loss: 30.7780\n",
      "Epoch 16/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 23.4528 - val_loss: 15.6390\n",
      "Epoch 17/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 19.4164 - val_loss: 14.8728\n",
      "Epoch 18/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 18.6290 - val_loss: 13.9689\n",
      "Epoch 19/100\n",
      "227/227 [==============================] - 0s 53us/step - loss: 18.4663 - val_loss: 13.5354\n",
      "Epoch 20/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 17.4996 - val_loss: 13.4578\n",
      "Epoch 21/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 17.1975 - val_loss: 14.1102\n",
      "Epoch 22/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 17.1424 - val_loss: 12.7617\n",
      "Epoch 23/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 16.8102 - val_loss: 12.4717\n",
      "Epoch 24/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.1148 - val_loss: 12.8268\n",
      "Epoch 25/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 16.0029 - val_loss: 12.4816\n",
      "Epoch 26/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 15.5801 - val_loss: 12.3524\n",
      "Epoch 27/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.4985 - val_loss: 12.6161\n",
      "Epoch 28/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 15.0007 - val_loss: 12.5535\n",
      "Epoch 29/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 14.9678 - val_loss: 12.2377\n",
      "Epoch 30/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 14.8248 - val_loss: 13.0338\n",
      "Epoch 31/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.6803 - val_loss: 13.3675\n",
      "Epoch 32/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.5185 - val_loss: 11.5925\n",
      "Epoch 33/100\n",
      "227/227 [==============================] - 0s 40us/step - loss: 14.0127 - val_loss: 11.6208\n",
      "Epoch 34/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 13.7616 - val_loss: 11.6454\n",
      "Epoch 35/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.5161 - val_loss: 12.3820\n",
      "Epoch 36/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 13.7074 - val_loss: 12.6590\n",
      "Epoch 37/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.4893 - val_loss: 11.7195\n",
      "Epoch 38/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.0910 - val_loss: 11.3950\n",
      "Epoch 39/100\n",
      "227/227 [==============================] - 0s 31us/step - loss: 13.1478 - val_loss: 11.7004\n",
      "Epoch 40/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 13.1168 - val_loss: 11.1616\n",
      "Epoch 41/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 12.6922 - val_loss: 11.2080\n",
      "Epoch 42/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.6021 - val_loss: 11.9059\n",
      "Epoch 43/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.3224 - val_loss: 12.8667\n",
      "Epoch 44/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 12.7555 - val_loss: 13.8226\n",
      "Epoch 45/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 13.0272 - val_loss: 12.3399\n",
      "Epoch 46/100\n",
      "227/227 [==============================] - 0s 39us/step - loss: 12.7440 - val_loss: 11.3210\n",
      "Epoch 47/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.2724 - val_loss: 11.3818\n",
      "Epoch 48/100\n",
      "227/227 [==============================] - 0s 44us/step - loss: 12.0241 - val_loss: 12.6540\n",
      "Epoch 49/100\n",
      "227/227 [==============================] - 0s 35us/step - loss: 12.1043 - val_loss: 11.9456\n",
      "Epoch 50/100\n",
      "227/227 [==============================] - 0s 48us/step - loss: 12.1328 - val_loss: 11.5715\n",
      "57/57 [==============================] - 0s 35us/step\n",
      "Train on 228 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "228/228 [==============================] - 0s 236us/step - loss: 525.4402 - val_loss: 292.7057\n",
      "Epoch 2/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 237.5001 - val_loss: 124.9622\n",
      "Epoch 3/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 106.3041 - val_loss: 52.2906\n",
      "Epoch 4/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 50.5779 - val_loss: 32.0250\n",
      "Epoch 5/100\n",
      "228/228 [==============================] - 0s 35us/step - loss: 35.4336 - val_loss: 25.6020\n",
      "Epoch 6/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 29.3143 - val_loss: 22.3908\n",
      "Epoch 7/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 26.9397 - val_loss: 21.0071\n",
      "Epoch 8/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 25.4635 - val_loss: 19.0751\n",
      "Epoch 9/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 23.9887 - val_loss: 18.5552\n",
      "Epoch 10/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 23.2430 - val_loss: 17.8265\n",
      "Epoch 11/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 21.9202 - val_loss: 17.9270\n",
      "Epoch 12/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 21.5038 - val_loss: 17.4551\n",
      "Epoch 13/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 21.0855 - val_loss: 16.5975\n",
      "Epoch 14/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 20.5920 - val_loss: 16.3253\n",
      "Epoch 15/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 19.8710 - val_loss: 15.9366\n",
      "Epoch 16/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 19.3991 - val_loss: 15.5172\n",
      "Epoch 17/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 19.0491 - val_loss: 15.0502\n",
      "Epoch 18/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 18.6920 - val_loss: 17.0695\n",
      "Epoch 19/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 18.3347 - val_loss: 14.9317\n",
      "Epoch 20/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 17.8840 - val_loss: 19.8824\n",
      "Epoch 21/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 19.5920 - val_loss: 15.7306\n",
      "Epoch 22/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 17.6477 - val_loss: 14.4894\n",
      "Epoch 23/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 17.0185 - val_loss: 14.5830\n",
      "Epoch 24/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 16.8284 - val_loss: 15.2441\n",
      "Epoch 25/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 16.6816 - val_loss: 14.9236\n",
      "Epoch 26/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 15.9253 - val_loss: 13.4360\n",
      "Epoch 27/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 15.7397 - val_loss: 15.6577\n",
      "Epoch 28/100\n",
      "228/228 [==============================] - 0s 61us/step - loss: 16.3475 - val_loss: 14.1911\n",
      "Epoch 29/100\n",
      "228/228 [==============================] - 0s 57us/step - loss: 15.4031 - val_loss: 12.6673\n",
      "Epoch 30/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 15.1343 - val_loss: 12.8209\n",
      "Epoch 31/100\n",
      "228/228 [==============================] - 0s 53us/step - loss: 14.7614 - val_loss: 12.2003\n",
      "Epoch 32/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 14.5537 - val_loss: 12.1276\n",
      "Epoch 33/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 14.5543 - val_loss: 11.9522\n",
      "Epoch 34/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 14.2298 - val_loss: 11.9902\n",
      "Epoch 35/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 13.9127 - val_loss: 13.3427\n",
      "Epoch 36/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 14.1427 - val_loss: 12.7769\n",
      "Epoch 37/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 13.9154 - val_loss: 11.7272\n",
      "Epoch 38/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 13.4134 - val_loss: 11.6413\n",
      "Epoch 39/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.3916 - val_loss: 11.9274\n",
      "Epoch 40/100\n",
      "228/228 [==============================] - 0s 35us/step - loss: 13.3243 - val_loss: 11.3254\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 0s 39us/step - loss: 13.1862 - val_loss: 11.8880\n",
      "Epoch 42/100\n",
      "228/228 [==============================] - 0s 52us/step - loss: 13.2651 - val_loss: 15.5618\n",
      "Epoch 43/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 15.3501 - val_loss: 11.6463\n",
      "Epoch 44/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 13.3955 - val_loss: 11.6387\n",
      "Epoch 45/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 13.2395 - val_loss: 11.3811\n",
      "Epoch 46/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.8050 - val_loss: 11.8023\n",
      "Epoch 47/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.9622 - val_loss: 11.2057\n",
      "Epoch 48/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.5715 - val_loss: 11.5773\n",
      "Epoch 49/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.6930 - val_loss: 12.2540\n",
      "Epoch 50/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.7434 - val_loss: 11.3498\n",
      "Epoch 51/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.4554 - val_loss: 11.4432\n",
      "Epoch 52/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.2281 - val_loss: 10.9637\n",
      "Epoch 53/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.3815 - val_loss: 10.9213\n",
      "Epoch 54/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.1687 - val_loss: 10.8383\n",
      "Epoch 55/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.0037 - val_loss: 11.7195\n",
      "Epoch 56/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.3634 - val_loss: 11.4170\n",
      "Epoch 57/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 12.1604 - val_loss: 11.2311\n",
      "Epoch 58/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 11.9373 - val_loss: 15.2935\n",
      "Epoch 59/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 14.0902 - val_loss: 11.4372\n",
      "Epoch 60/100\n",
      "228/228 [==============================] - 0s 48us/step - loss: 12.0066 - val_loss: 11.4680\n",
      "Epoch 61/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 11.8427 - val_loss: 15.7810\n",
      "Epoch 62/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 12.6832 - val_loss: 11.5272\n",
      "Epoch 63/100\n",
      "228/228 [==============================] - 0s 39us/step - loss: 11.5334 - val_loss: 11.8140\n",
      "Epoch 64/100\n",
      "228/228 [==============================] - 0s 44us/step - loss: 11.5780 - val_loss: 12.6493\n",
      "56/56 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/100\n",
      "284/284 [==============================] - 0s 175us/step - loss: 483.0168 - val_loss: 229.2621\n",
      "Epoch 2/100\n",
      "284/284 [==============================] - 0s 42us/step - loss: 161.8416 - val_loss: 58.0143\n",
      "Epoch 3/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 58.3325 - val_loss: 30.4135\n",
      "Epoch 4/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 37.7809 - val_loss: 21.9581\n",
      "Epoch 5/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 30.9057 - val_loss: 19.3186\n",
      "Epoch 6/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 28.1161 - val_loss: 17.5691\n",
      "Epoch 7/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 26.4056 - val_loss: 16.7587\n",
      "Epoch 8/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 24.7063 - val_loss: 16.0696\n",
      "Epoch 9/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 23.6734 - val_loss: 15.7181\n",
      "Epoch 10/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 22.5264 - val_loss: 15.2242\n",
      "Epoch 11/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 21.4905 - val_loss: 14.8119\n",
      "Epoch 12/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 20.7032 - val_loss: 14.4608\n",
      "Epoch 13/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 19.8383 - val_loss: 13.8762\n",
      "Epoch 14/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 18.8825 - val_loss: 13.6067\n",
      "Epoch 15/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 18.3478 - val_loss: 13.2284\n",
      "Epoch 16/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 17.5896 - val_loss: 13.0748\n",
      "Epoch 17/100\n",
      "284/284 [==============================] - 0s 28us/step - loss: 17.0644 - val_loss: 12.6004\n",
      "Epoch 18/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 16.8093 - val_loss: 12.3315\n",
      "Epoch 19/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 16.0180 - val_loss: 12.3846\n",
      "Epoch 20/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 15.5687 - val_loss: 11.8631\n",
      "Epoch 21/100\n",
      "284/284 [==============================] - 0s 42us/step - loss: 15.1970 - val_loss: 11.6266\n",
      "Epoch 22/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 14.9480 - val_loss: 11.4387\n",
      "Epoch 23/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 14.6173 - val_loss: 11.4559\n",
      "Epoch 24/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 14.0603 - val_loss: 11.1704\n",
      "Epoch 25/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 14.0147 - val_loss: 11.2350\n",
      "Epoch 26/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 13.5693 - val_loss: 11.1365\n",
      "Epoch 27/100\n",
      "284/284 [==============================] - 0s 39us/step - loss: 13.2949 - val_loss: 10.8369\n",
      "Epoch 28/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 13.0126 - val_loss: 10.8456\n",
      "Epoch 29/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 12.8933 - val_loss: 10.8905\n",
      "Epoch 30/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 12.7960 - val_loss: 10.7007\n",
      "Epoch 31/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 12.4572 - val_loss: 10.9120\n",
      "Epoch 32/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 12.3840 - val_loss: 10.7059\n",
      "Epoch 33/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 12.1920 - val_loss: 10.6861\n",
      "Epoch 34/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 12.1086 - val_loss: 10.9205\n",
      "Epoch 35/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 11.9080 - val_loss: 10.7204\n",
      "Epoch 36/100\n",
      "284/284 [==============================] - 0s 32us/step - loss: 11.8125 - val_loss: 10.6761\n",
      "Epoch 37/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 11.5757 - val_loss: 10.7199\n",
      "Epoch 38/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 11.5403 - val_loss: 10.7231\n",
      "Epoch 39/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 11.2727 - val_loss: 10.8069\n",
      "Epoch 40/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 11.3202 - val_loss: 11.0893\n",
      "Epoch 41/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 11.1237 - val_loss: 10.9063\n",
      "Epoch 42/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 11.2364 - val_loss: 10.9381\n",
      "Epoch 43/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 10.9039 - val_loss: 10.9721\n",
      "Epoch 44/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 10.7906 - val_loss: 11.1578\n",
      "Epoch 45/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 10.7200 - val_loss: 10.9964\n",
      "Epoch 46/100\n",
      "284/284 [==============================] - 0s 35us/step - loss: 10.6716 - val_loss: 11.1079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000001C8F8DEBC88>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001C887ECD3C8>,\n",
       "                                        'n_hidden': [1, 2, 3, 4],\n",
       "                                        'units': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15...\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from scipy.stats import reciprocal\n",
    "param_dis = {\n",
    "    'n_hidden' : [1,2,3,4],\n",
    "    'units': np.arange(1,100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "grid = RandomizedSearchCV(model, param_dis, n_iter=10, cv = 5)\n",
    "early_cb = EarlyStopping(patience=10)\n",
    "grid.fit(X_train, y_train, epochs = 100, validation_data = (X_valid, y_valid), callbacks = [early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.176206263018326"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0023984711378724883, 'n_hidden': 1, 'units': 37}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1c89021f278>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
