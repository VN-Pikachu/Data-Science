{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".box {\n",
       "    border: 1px double dodgerblue;\n",
       "    padding: 5px;\n",
       "}\n",
       ".note {\n",
       "    font-size: 20;\n",
       "    color: teal;\n",
       "    font-weight: bold;\n",
       "}\n",
       ".highlight {\n",
       "    color: green;\n",
       "    font-family: verdana;\n",
       "}\n",
       ".tag {\n",
       "    background: red;\n",
       "    color: white;\n",
       "    padding: 3px;\n",
       "}\n",
       ".warning {\n",
       "    background: red;\n",
       "    padding: 12px;\n",
       "    font-size: 24px;\n",
       "    color: white;\n",
       "    text-align: center;\n",
       "    font-family: verdana;\n",
       "}\n",
       ".symbol {\n",
       "    color: white;\n",
       "    background: green;\n",
       "    font-size: 20px;\n",
       "    padding: 2px;\n",
       "}\n",
       "code {\n",
       "    font-weight: bold;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run ../convention.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining on an auxiliary task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will build a DNN that compares two MNIST digit images and predicts whether they represent the same digit or not. Then you will reuse the lower layers of this network to train an MNIST classifier using very little training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'note'>Exercise: Start by building two DNNs (let's call them DNN A and B), both similar to the one you built earlier but without the output layer: each DNN should have five hidden layers of 100 neurons each, He initialization, and ELU activation. Next, add one more hidden layer with 10 units on top of both DNNs. You should use the keras.layers.concatenate() function to concatenate the outputs of both DNNs, then feed the result to the hidden layer. Finally, add an output layer with a single neuron using the logistic activation function.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Flatten, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 784)          0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 784)          0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 100)          78500       flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 100)          78500       flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 100)          10100       dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 100)          10100       dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 100)          10100       dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 100)          10100       dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 100)          10100       dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 100)          10100       dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 100)          10100       dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 100)          10100       dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 200)          0           dense_52[0][0]                   \n",
      "                                                                 dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 10)           2010        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 1)            11          dense_58[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 239,821\n",
      "Trainable params: 239,821\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generate_model(input_layer):\n",
    "    layer = Flatten()(input_layer)\n",
    "    for i in range(5):\n",
    "        layer = Dense(100, activation = 'elu', kernel_initializer='he_normal')(layer)\n",
    "    return layer\n",
    "input_1 = Input(shape = (28,28))\n",
    "input_2 = Input(shape = (28,28))\n",
    "DNN1 = generate_model(input_1)\n",
    "DNN2 = generate_model(input_2)\n",
    "concat = concatenate([DNN1, DNN2])\n",
    "hidden = Dense(10, activation='elu',kernel_initializer='he_normal')(concat)\n",
    "output = Dense(1, activation='sigmoid')(hidden)\n",
    "model = Model(inputs = [input_1, input_2], outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'note'>\n",
    "Exercise: split the MNIST training set in two sets: split #1 should containing 55,000 images, and split #2 should contain contain 5,000 images. Create a function that generates a training batch where each instance is a pair of MNIST images picked from split #1. Half of the training instances should be pairs of images that belong to the same class, while the other half should be images from different classes. For each pair, the training label should be 0 if the images are from the same class, or 1 if they are from different classes.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_split_1, X_split_2 = X_train[5000:] , X_train[:5000] \n",
    "y_split_1, y_split_2 = y_train[5000:], y_train[:5000]\n",
    "X_split_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for num in range(10):\n",
    "    is_num = X_split_1[y_split_1 == num]\n",
    "    not_num = X_split_1[y_split_1 != num]\n",
    "    for _ in range(500):\n",
    "        i, j, p = is_num[np.random.choice(len(is_num), size = 3)]\n",
    "        q = not_num[np.random.choice(len(not_num))]\n",
    "        data.append([i, j, 1])\n",
    "        data.append([p, q, 0])\n",
    "np.random.shuffle(data)\n",
    "X1, X2, y = np.array([arr[0] for arr in data]), np.array([arr[1] for arr in data]), np.array([arr[2] for arr in data])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class = 'note'>\n",
    "Exercise: train the DNN on this training set. For each image pair, you can simultaneously feed the first image to DNN A and the second image to DNN B. The whole network will gradually learn to tell whether two images belong to the same class or not.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint_cb = ModelCheckpoint('mnist_binary.h5', save_best_only=True)\n",
    "early_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "model.compile('rmsprop', 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10000/10000 [==============================] - 1s 112us/step - loss: 1.3889 - accuracy: 0.4974\n",
      "Epoch 2/30\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.6936 - accuracy: 0.4942\n",
      "Epoch 3/30\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.6933 - accuracy: 0.5014\n",
      "Epoch 4/30\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.6935 - accuracy: 0.4876\n",
      "Epoch 5/30\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.6935 - accuracy: 0.4912\n",
      "Epoch 6/30\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.6934 - accuracy: 0.4958\n",
      "Epoch 7/30\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.6934 - accuracy: 0.4982\n",
      "Epoch 8/30\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.6934 - accuracy: 0.4990\n",
      "Epoch 9/30\n",
      "10000/10000 [==============================] - 1s 91us/step - loss: 0.6935 - accuracy: 0.4916\n",
      "Epoch 10/30\n",
      "10000/10000 [==============================] - 1s 90us/step - loss: 0.6935 - accuracy: 0.4922\n",
      "Epoch 11/30\n",
      "10000/10000 [==============================] - 1s 92us/step - loss: 0.6933 - accuracy: 0.5068\n",
      "Epoch 12/30\n",
      "10000/10000 [==============================] - 1s 93us/step - loss: 0.6935 - accuracy: 0.4990\n",
      "Epoch 13/30\n",
      "10000/10000 [==============================] - 1s 107us/step - loss: 0.6935 - accuracy: 0.4978\n",
      "Epoch 14/30\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.6934 - accuracy: 0.4974\n",
      "Epoch 15/30\n",
      "10000/10000 [==============================] - 1s 105us/step - loss: 0.6934 - accuracy: 0.4990\n",
      "Epoch 16/30\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 0.6935 - accuracy: 0.4902\n",
      "Epoch 17/30\n",
      "10000/10000 [==============================] - 1s 93us/step - loss: 0.6934 - accuracy: 0.4984\n",
      "Epoch 18/30\n",
      "10000/10000 [==============================] - 1s 110us/step - loss: 0.6934 - accuracy: 0.5048\n",
      "Epoch 19/30\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 0.6935 - accuracy: 0.4926\n",
      "Epoch 20/30\n",
      "10000/10000 [==============================] - 1s 99us/step - loss: 0.6935 - accuracy: 0.4944\n",
      "Epoch 21/30\n",
      "10000/10000 [==============================] - 1s 99us/step - loss: 0.6932 - accuracy: 0.5082\n",
      "Epoch 22/30\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 0.6935 - accuracy: 0.4966\n",
      "Epoch 23/30\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 0.6935 - accuracy: 0.4962\n",
      "Epoch 24/30\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 0.6934 - accuracy: 0.5018\n",
      "Epoch 25/30\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.6933 - accuracy: 0.5002\n",
      "Epoch 26/30\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 0.6935 - accuracy: 0.4954\n",
      "Epoch 27/30\n",
      "10000/10000 [==============================] - 1s 98us/step - loss: 0.6934 - accuracy: 0.5006\n",
      "Epoch 28/30\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 0.6935 - accuracy: 0.4986\n",
      "Epoch 29/30\n",
      "10000/10000 [==============================] - 1s 123us/step - loss: 0.6934 - accuracy: 0.5020\n",
      "Epoch 30/30\n",
      "10000/10000 [==============================] - 1s 109us/step - loss: 0.6935 - accuracy: 0.4988\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X1, X2], y, callbacks = [checkpoint_cb, early_cb], epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5000, 5000], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
